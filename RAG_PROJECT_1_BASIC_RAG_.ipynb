{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvGUJ_kt18Eu"
      },
      "source": [
        "User Question\n",
        "   ↓\n",
        "Embed Question\n",
        "   ↓\n",
        "FAISS Similarity Search\n",
        "   ↓\n",
        "Top-k Wikipedia Chunks\n",
        "   ↓\n",
        "Prompt Construction\n",
        "   ↓\n",
        "LLM Answer (grounded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBppStuD18dq",
        "outputId": "cb8241fa-ad69-4185-d2a2-3a0c6bb2075c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.13.2\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu sentence-transformers transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AxSDrT26R6M",
        "outputId": "b250ca30-2bba-4d6d-9776-99392c576eae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-6.6.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2026.1.4)\n",
            "Downloading pypdf-6.6.2-py3-none-any.whl (329 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.1/329.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-6.6.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf sentence-transformers faiss-cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bXzWgmkR8jqn"
      },
      "outputs": [],
      "source": [
        "from pypdf import PdfReader\n",
        "from sentence_transformers import SentenceTransformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6GSr-rW8uSA",
        "outputId": "63639ff8-b766-4b58-8a8b-813c8e4f5600"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Advanced RAG Models with Graph Structures: \n",
            "Optimizing Complex Knowledge Reasoning and Text \n",
            "Generation \n",
            "  \n",
            "  \n",
            "  \n",
            "  \n",
            " \n",
            "  \n",
            "  \n",
            "  \n",
            "  \n",
            " \n",
            "  \n",
            "  \n",
            "  \n",
            "  \n",
            " \n",
            "  \n",
            "  \n",
            "  \n",
            " \n",
            "  \n",
            "  \n",
            "  \n",
            " \n",
            "  \n",
            "  \n",
            "  \n",
            "  \n",
            " \n",
            " \n",
            "Abstract—This study aims to optimize the existing \n",
            "retrieval-augmented generation model (RAG) by \n",
            "introducing a graph structure to improve the performance \n",
            "of the model in dealing with complex knowledge reasoning \n",
            "tasks. The traditional RAG model has the problem of \n",
            "insufficient processing efficiency when facing complex \n",
            "graph structure information (such as knowledge graphs, \n",
            "hierarchical relationships, etc.), which affects the quality \n",
            "and consistency of the generated results. This study \n",
            "proposes a scheme to process graph structure data by \n",
            "combining graph neural network (GNN), so that the model \n",
            "can capture the complex relationship between entities, \n",
            "thereby improving the knowledge consistency and \n",
            "reasoning ability of the generated text. The experiment \n",
            "used the Natural Questions (NQ) dataset and compared it \n",
            "with multiple existing generation models. The results show \n",
            "that the graph-based RAG model proposed in this paper is \n",
            "superior to the traditional generation model in terms of \n",
            "quality, knowledge consistency , and reasoning ability, \n",
            "especially when dealing with tasks that require multi -\n",
            "dimensional reasoning. Through the combination of the \n",
            "enhancement of the retrieval module and the graph neural \n",
            "network, the model in this study can better handle complex \n",
            "knowledge background information and has broad \n",
            "potential value in multiple practical application scenarios. \n",
            "Keywords-Graph neural network, retrieval -enhanced \n",
            "generation, knowledge consistency, reasoning ability \n",
            "I.  INTRODUCTION  \n",
            "At present, generative models have shown great potential in \n",
            "many application fields  [1]. However, traditional generative \n",
            "language models mainly rely on a large amount of pre -trained \n",
            "data for learning. Although these models can generate \n",
            "relatively coherent text, their generation ability is still limited \n",
            "when facing external knowledge or complex background \n",
            "information. To this end, the retrieval -augmented generation \n",
            "model (RAG) came into being. By combining the retrieval \n",
            "system with the generation model, it can dynamically access \n",
            "external knowledge during the generation process, thereby \n",
            "greatly improving the quality and accuracy of generation. \n",
            "Especially in tasks that require a rich knowledge background or \n",
            "complex reasoning, the RAG model shows stronger advantages \n",
            "than the single-generation model [2]. \n",
            "However, the existing RAG model still has certain \n",
            "limitations [3]. First, the retrieval module of the RAG model is \n",
            "usually text-based, which means that it is difficult to effectively \n",
            "process complex structured information (such as graph \n",
            "structure [4], hierarchical relationship  [5], etc.). In practical \n",
            "applications, a lot of knowledge has inherent structured \n",
            "characteristics, especially in scenarios such as knowledge \n",
            "graphs [6], social networks, scientific literature, etc., where \n",
            "information is not just discrete text fragments, but has a high \n",
            "degree of association and contextual relationship [7-8]. Faced \n",
            "with this complex graph structure information, traditional RAG \n",
            "models are often difficult to fully utilize, thus affecting the \n",
            "generation effect. Secondly, the synergy between the retrieval \n",
            "module and the generation module still needs to be further \n",
            "optimized. Although the current RAG model can use external \n",
            "information to enhance the generation effect, it still has \n",
            "inaccurate or incoherent generation results when dealing with \n",
            "complex reasoning tasks, which limits its application in some \n",
            "high-demand scenarios [9]. \n",
            "In order to solve the above problems, the RAG model \n",
            "combined with graph structure has gradually become a hot \n",
            "topic of research. Graph structure data can express the complex \n",
            "relationship between different objects in the form of nodes and \n",
            "edges, so it is widely used in many fields , such as knowledge \n",
            "graphs [10], financial networks [11], and medical analysis.[12]. \n",
            "By introducing technologies such as graph neural networks \n",
            "(GNNs), RAG models can better process structured knowledge \n",
            "and extract valuable information from them for the generation \n",
            "process. For example, in the knowledge graph, each node \n",
            "represents an entity and the edge represents the relationship \n",
            "between entities. The graph neural network can effectively \n",
            "capture this association structure, so that the model can access \n",
            "Yu x in Dong\n",
            "Wake Forest University\n",
            "Winston-Salem, USA\n",
            "Shuo Wang\n",
            "Purdue University\n",
            "Indianapolis, USA\n",
            "Hongye Zheng\n",
            "The Chinese University of Hong Kong \n",
            "Hong Kong, China\n",
            "Chihang Wang *\n",
            "New Yo rk University\n",
            "New Yo rk, USA\n",
            "Zhenhong Zhang\n",
            "George Washington University \n",
            "Washington, USA\n",
            "������������\n",
            "��������������������\n",
            "�������������\n",
            "richer contextual information when generating. This RAG \n",
            "model combined with graph structure can better cope with \n",
            "complex knowledge reasoning tasks and significantly improve \n",
            "the generation quality and rationality of the model. \n",
            "In practical applications, the RAG model based on graph \n",
            "structure has a wide range of potential values. In the medical \n",
            "field, the graph RAG model can be used for medical record \n",
            "generation and diagnosis assistance. Medical records usually \n",
            "contain a variety of structured information such as the patient's \n",
            "historical condition, diagnosis, and treatment plan. The graph -\n",
            "based model can better handle the association between this \n",
            "information and generate reports or suggestions with diagnostic \n",
            "value [13]. In short, the optimization and application research \n",
            "of the graph -based retrieval enhancement generation model \n",
            "RAG has important practical significance and broad application \n",
            "prospects. By introducing graph structure information, the \n",
            "RAG model can demonstrate stronger expressiveness in \n",
            "processing complex knowledge reasoning and generation tasks. \n",
            "At the same time, with the continuous development of \n",
            "technologies such as graph neural networks, the graph RAG \n",
            "model will also usher in more optimization and application \n",
            "opportunities in the future, providing technical support for \n",
            "intelligent generation in more fields. \n",
            "II. RELATED WORK \n",
            "This study enhances the Retrieval -Augmented Generation \n",
            "(RAG) model by incorporating graph structures through Graph \n",
            "Neural Networks (GNNs) to support complex reasoning and \n",
            "improve generation quality. Prior research has informed \n",
            "various aspects of this work, from foundational NLP \n",
            "improvements to methodologies for structuring and processing \n",
            "complex, interconnected data. \n",
            "A central component of the RAG model is the transformer \n",
            "architecture, which has been instrumental in handling semantic \n",
            "complexity. Du et al. [14] discuss transformers' applications in \n",
            "managing intricate semantic information in natural language \n",
            "processing (NLP), highlighting the mechanisms that allow \n",
            "models to capture nuanced relationships within text. Such \n",
            "advancements are directly relevant to this study’s aim to \n",
            "process complex graph structures within RAG models, \n",
            "enhancing retrieval capabilities and accuracy in text generation. \n",
            "Several studies have contributed to understanding \n",
            "structured knowledge processing through GNNs and other \n",
            "embedding techniques. Wei et al. [15] propose a self -\n",
            "supervised GNN model that improves feature extraction across \n",
            "heterogeneous information networks, a methodology closely \n",
            "aligned with this paper's approach. Their techniques provide a \n",
            "foundation for integrating GNNs in RAG models, improving \n",
            "the model’s ability to understand complex associations within \n",
            "structured knowledge, such as in knowledge graphs. Similarly, \n",
            "Yang et al. [16] demonstrated the potential of dynamic \n",
            "hypergraphs in managing sequences and associations within \n",
            "data, supporting the notion that graph -enhanced models can \n",
            "effectively capture interconnected information within \n",
            "knowledge-rich domains. \n",
            "The model's retrieval module benefits from embedding \n",
            "strategies and attention mechanisms for feature enhancement, \n",
            "as highlighted by Liu et al. [17]. Their work on using \n",
            "separation embedding and self -attention strengthens \n",
            "understanding of how embeddings can improve interpretability \n",
            "and contextual sensitivity, both crucial for this paper’s RAG \n",
            "model in ensuring knowledge consistency and coherence. Cang \n",
            "et al. [18] also explore ensemble methods with transformer -\n",
            "based models to handle specialized datasets, providing insight \n",
            "into techniques for augmenting model adaptability when \n",
            "working with structured, domain-specific information. \n",
            "Another relevant contribution involves approaches for \n",
            "model optimization and improved robustness in handling \n",
            "structured data. Jiang et al. [19] developed a weighted \n",
            "adversarial network to enhance cross -domain consistency, a \n",
            "concept that aligns with the present study’s objective to \n",
            "improve the accuracy and reliability of generated responses \n",
            "when handling multifaceted knowledge. Additionally, Xu et al. \n",
            "[20] applied deep learning architectures to predict sequential \n",
            "and temporally linked information, exemplifying effective \n",
            "strategies for embedding temporal relationships that mirror the \n",
            "graph structure's role in maintaining logical flow within \n",
            "generated text. \n",
            "Moreover, the integration of interpretable data \n",
            "transformations, such as Yan et al.’s [21] transformation of \n",
            "multidimensional time series into interpretable sequences, \n",
            "underscores the value of structured data processing. These \n",
            "methods inform this study’s approach to embedding graph \n",
            "structures in the RAG model to improve interpretability and \n",
            "coherence across generated content, particularly for complex \n",
            "reasoning tasks. \n",
            "III. METHOD \n",
            " \n",
            "In this study, we proposed a graph-based retrieval-enhanced \n",
            "generation model (RAG) optimization scheme, and combined it \n",
            "with a graph neural network (GNN) to process graph structure \n",
            "information, thereby improving the model's generation ability \n",
            "in complex scenarios. To achieve this goal, our model \n",
            "framework mainly consists of three parts: graph structure \n",
            "processing module, retrieval module, and generation module as \n",
            "shown in Figure 1. \n",
            " \n",
            "Figure 1 Graph network architecture \n",
            "First, in the graph structure processing module, a graph \n",
            "neural network is used to encode the graph structure data. \n",
            "Assume that a graph structure can be represented as \n",
            "),( EVG =\n",
            ", where V is a set of nodes and E is a set of edges. \n",
            "Each node \n",
            "Vv   represents an entity or object, and edge\n",
            "),( ji vve =\n",
            " represents the relationship between nodes \n",
            "iv  and \n",
            "jv\n",
            ". For each node, we first represent its initial feature as \n",
            "0\n",
            "ih  \n",
            "and then update the representation of each node through the \n",
            "propagation mechanism of the graph neural network. The basic \n",
            "propagation mechanism of graph neural networks can be \n",
            "defined as: \n",
            "))})(:({( )()()()1( kk\n",
            "j\n",
            "kk\n",
            "i biNjhAGGWh +=+ \n",
            " \n",
            " \n",
            "Among them, \n",
            ")(iN  represents the set of neighbor nodes of \n",
            "node \n",
            "iv , AGG is the aggregation function, common \n",
            "aggregation methods include average, sum or maximum, \n",
            ")(  \n",
            "is the nonlinear activation function, \n",
            ")(kW and \n",
            ")(kb are the \n",
            "weight matrix and bias term of the kth layer respectively. After \n",
            "multiple layers of propagation and updating, we can get the \n",
            "final representation \n",
            ")(L\n",
            "ih  of each node, where L is the number \n",
            "of layers of the graph neural network.  \n",
            "Next, in the retrieval module, we perform retrieval in \n",
            "combination with graph structure information. In order to \n",
            "improve retrieval efficiency, we adopt a retrieval method based \n",
            "on graph embedding. Suppose we have a knowledge base K, \n",
            "which contains multiple knowledge fragments, each of which \n",
            "can be represented by a graph structure as \n",
            "kG . We first \n",
            "perform graph encoding on each \n",
            "kG  to obtain the embedding \n",
            "vector \n",
            "kz  of each knowledge fragment. Then, for the input \n",
            "query, we also generate the graph embedding vector \n",
            "qz  of the \n",
            "query through the graph neural network, and calculate the \n",
            "similarity between the query and each knowledge fragment in \n",
            "the knowledge base through the similarity between the vectors \n",
            "(cosine similarity): \n",
            "||||||||),(\n",
            "kq\n",
            "kq\n",
            "kq\n",
            "zz\n",
            "zzzzsim =\n",
            " \n",
            "The knowledge fragments with the highest similarity will \n",
            "be retrieved as the input of the generation module. This graph -\n",
            "based retrieval method can more effectively capture complex \n",
            "entity relationships and improve the accuracy of retrieval. \n",
            "Finally, in the generation module, we use a generation \n",
            "model based on Chatgpt4.0 to generate text. Assuming that the \n",
            "retrieval module returns relevant knowledge fragments, each \n",
            "knowledge fragment is represented as a vector, we embed these \n",
            "retrieved knowledge fragments and input the query into the \n",
            "generation model together. During the generation process, the \n",
            "generation model will dynamically adjust the generation \n",
            "strategy according to the relevant information of these \n",
            "knowledge fragments to improve the relevance and accuracy of \n",
            "the generation results. \n",
            "Specifically, the goal of the generation process is to \n",
            "maximize the conditional probability \n",
            "),...,,,|( 21 NzzzqyP\n",
            "given a query\n",
            "q and retrieved \n",
            "knowledge fragment \n",
            "Nzzz ,...,, 21 , where \n",
            "y  represents the \n",
            "generated target text. This conditional probability can be \n",
            "represented by the output distribution of the generation model: \n",
            ")max(),...,,,,|( 21 otoNtt bhWsoftzzzqyyP +=\n",
            " \n",
            "Among them, \n",
            "ty  represents the t -th word generated,\n",
            "ty  \n",
            "represents the first t -1 words generated, \n",
            "th is the hidden state \n",
            "of the generative model at time step t, and \n",
            "oW  and \n",
            "ob  are the \n",
            "parameters of the output layer. By continuously generating the \n",
            "next word until the generation end mark is reached, the model \n",
            "can complete the generation of the entire text. \n",
            "In summary, this method introduces graph neural networks \n",
            "to process graph structured data and combines it with a \n",
            "retrieval-enhanced generation model to effectively utilize \n",
            "external knowledge in the generation process, thereby \n",
            "achieving better generation effects for complex knowledge \n",
            "scenarios. \n",
            "IV. EXPERIMENT \n",
            "A. Introduction to the dataset and the LLM used \n",
            "In this experiment, we used a generative model based on \n",
            "ChatGPT-4 as the core part of the experiment. ChatGPT -4 is a \n",
            "large-scale pre-trained language model developed by OpenAI. \n",
            "It is based on the Transformer architecture and can generate \n",
            "natural and coherent text [22]. ChatGPT-4 has strong language \n",
            "understanding and generation capabilities and can handle a \n",
            "wide range of text -generation tasks. However, in order to \n",
            "further improve the performance in knowledge -intensive and \n",
            "reasoning tasks, we combined the design of the RAG (Retrieval \n",
            "Augmented Generation) model to dynamically obtain relevant \n",
            "information from external knowledge bases through the \n",
            "retrieval module to generate more knowledge -accurate and \n",
            "relevant answers. This architecture can effectively make up for \n",
            "the problem that the generative model relies solely on training \n",
            "data, enabling it to handle knowledge reasoning and complex \n",
            "tasks in more fields. \n",
            "In our experiments, we used the Natural Questions (NQ) \n",
            "dataset, which is widely used for retrieval and generation tasks. \n",
            "NQ is an open-domain question-answering dataset that contains \n",
            "real question queries from users, accompanied by relevant \n",
            "document snippets automatically retrieved from Internet \n",
            "resources such as Wikipedia. Each data sample consists of a \n",
            "query, a retrieved document, and an answer, covering a wide \n",
            "range of content in multiple fields such as history, science, and \n",
            "culture. The diversity of the NQ dataset makes it an ideal \n",
            "choice for evaluating the performance and reasoning ability of \n",
            "generative models on complex domain problems. This \n",
            "experiment uses this dataset to test the retrieval and generation \n",
            "capabilities of our model to evaluate the accuracy and \n",
            "knowledge completeness of its generated text. \n",
            "This experiment is run in a high -performance computing \n",
            "environment. The experimental hardware configuration \n",
            "includes NVIDIA A100 GPU, 128GB memory and 64 -core \n",
            "CPU, which can support efficient training and reasoning of \n",
            "large-scale models. The experimental software is mainly based\n",
            "on the PyTorch framework for model training and evaluation, \n",
            "and combines Hugging Face's Transformers library to \n",
            "implement the retrieval and generation functions of the RAG \n",
            "model. \n",
            "B. Experimental Results \n",
            "We will select five different generative models to conduct \n",
            "comparative experiments with the RAG model based on graph \n",
            "structure optimization proposed in this paper (labeled as Ours). \n",
            "By comparing their performance on the same dataset, we can \n",
            "verify the superiority of our model. The evaluation indicators \n",
            "used in the comparative experiments include Quality, \n",
            "Knowledge Consistency (KC), and Reasoning Capability(RC). \n",
            "Table 1 Experimental Results \n",
            "Model Quality KC RC \n",
            "BART 0.74 0.65 0.68 \n",
            "T5 0.78 0.68 0.72 \n",
            "RAG 0.82 0.73 0.80 \n",
            "RAG+T 0.85 0.76 0.84 \n",
            "FID 0.87 0.78 0.87 \n",
            "ours 0.90 0.85 0.91 \n",
            " \n",
            "From the experimental results as shown in Table 1, the \n",
            "performance of each model in the three indicators of Quality, \n",
            "Knowledge Consistency, and Reasoning Capability varies. It \n",
            "can be observed that traditional generative models such as \n",
            "BART and T5 performed relatively weakly in the experiment, \n",
            "especially in terms of knowledge consistency and reasoning \n",
            "capability. BART's quality score is 0.74, KC score is 0.65, and \n",
            "reasoning capability is 0.68, reflecting that although its \n",
            "generated text is fluent, it cannot provide sufficient external \n",
            "support in knowledge -intensive tasks. The T5 model has a \n",
            "slight improvement in the three indicators, especially in \n",
            "reasoning capability (0.72), which shows that the T5 model can \n",
            "improve its generalization ability by unifying task processing, \n",
            "but it is still not enough to fully handle complex knowledge \n",
            "reasoning tasks. \n",
            "In contrast, the RAG model and its improved version \n",
            "RAG+T (RAG+Text) perform significantly better than BART \n",
            "and T5 in these three indicators. The RAG model combines the \n",
            "retrieval module to enable it to dynamically access the external \n",
            "knowledge base during the generation process, thereby \n",
            "significantly improving knowledge consistency (0.73) and \n",
            "reasoning capability (0.80). The performance of RAG+T is \n",
            "further improved, especially in terms of reasoning ability, \n",
            "which reaches 0.84, which shows the great potential of \n",
            "retrieval-enhanced generative models in complex tasks. By \n",
            "incorporating more relevant knowledge into the generation \n",
            "process, RAG+T shows stronger ability to deal with complex \n",
            "background information and deep reasoning, further narrowing \n",
            "the limitations of generative models in dealing with \n",
            "knowledge-intensive tasks. \n",
            "Finally, the graph -based RAG optimization model (ours) \n",
            "proposed in this paper performs well in all indicators, with a \n",
            "quality score of 0.90, knowledge consistency of 0.85, and \n",
            "reasoning ability of 0.91, which is significantly better than \n",
            "other models. This result verifies the effectiveness of our \n",
            "introduction of graph structure information. The graph neural \n",
            "network can capture the complex relationship between nodes \n",
            "and edges in the data, enabling the model to better handle \n",
            "complex knowledge reasoning tasks during the generation \n",
            "process and generate text with higher knowledge consistency. \n",
            "In addition, our model performs particularly well in reasoning \n",
            "ability, showing that when faced with complex problems, the \n",
            "retrieval-enhanced model combined with the graph structure \n",
            "can generate answers more accurately, indicating that the graph \n",
            "RAG model has significant advantages in dealing with \n",
            "generation tasks with structured knowledge. Overall, our model \n",
            "not only improves the generation quality, but also greatly \n",
            "improves the knowledge accuracy and reasoning depth of the \n",
            "generated text while maintaining a high generation speed. \n",
            "At the same time, we also let the model perform generation \n",
            "tasks under the conditions of retrieving 1, 3, 5, and 10 \n",
            "documents to observe the performance of the model under \n",
            "different document scales. \n",
            "Table 2  Experimental results of different document sizes \n",
            "Number of \n",
            "documents \n",
            "Quality KC RC \n",
            "1 0.83 0.81 0.82 \n",
            "3 0.87 0.83 0.88 \n",
            "5 0.89 0.85 0.90 \n",
            "10 0.89 0.85 0.91 \n",
            " \n",
            "From the experimental results in Table 2, it can be seen that \n",
            "with the increase in the number of retrieved documents, the \n",
            "quality, knowledge -KC, and RC of the model have all been \n",
            "significantly improved, but after the number of documents \n",
            "increases to a certain extent, this improvement tends to be flat. \n",
            "When retrieving 1 document, the quality, knowledge \n",
            "consistency, and reasoning ability of the model are 0.83, 0.81, \n",
            "and 0.82, respectively. This shows that although a single \n",
            "document can provide some effective information, due to the \n",
            "limitation of the amount of information, the model is weak in \n",
            "complex reasoning and knowledge integration, and the \n",
            "generated results are limited. \n",
            "As the number of documents increases to 3, the model has \n",
            "been significantly improved in all indicators, with the quality \n",
            "reaching 0.87 and the reasoning ability also increased to 0.88. \n",
            "This shows that more documents can provide a richer source of \n",
            "knowledge, significantly enhancing the reasoning depth and \n",
            "knowledge consistency of the model. When the number of \n",
            "documents increases to 5, the model performs best, with quality, \n",
            "knowledge consistency, and reasoning ability of 0.89, 0.85, and \n",
            "0.90, respectively, showing the best balance effect. However, \n",
            "when the number of documents further increased to 10, the \n",
            "model's reasoning ability slightly improved to 0.91, but the \n",
            "quality and knowledge consistency did not improve further, \n",
            "remaining at 0.89 and 0.85. This shows that too many \n",
            "documents will lead to information redundancy, resulting in the \n",
            "model being unable to effectively utilize these additional \n",
            "knowledge fragments, and the gain is limited. \n",
            "V. CONCLUSION \n",
            "The retrieval-augmented generation model (RAG) based on \n",
            "graph structure optimization proposed in this study introduces\n",
            "graph neural network (GNN) to process structured graph data, \n",
            "which significantly improves the performance of the model in \n",
            "complex reasoning tasks. Experimental results show that the \n",
            "RAG model combined with graph structure information is \n",
            "superior to traditional generation models in terms of generation \n",
            "quality, knowledge consistency and reasoning ability, \n",
            "especially when dealing with multi -document retrieval. When \n",
            "the number of document retrieval is moderate, the model can \n",
            "effectively utilize the external knowledge base to achieve \n",
            "higher quality generated text, and perform well in reasoning \n",
            "tasks with complex background information. \n",
            "Although increasing the number of retrieved documents can \n",
            "improve the reasoning ability of the model to a certain extent, \n",
            "when the number of documents is too large, information \n",
            "redundancy will affect the generation quality and knowledge \n",
            "consistency, and the gain effect is limited. This shows that \n",
            "there is an optimal balance point for the amount of information \n",
            "retrieved, and beyond this point, the performance improvement \n",
            "of the model tends to be flat. Overall, the graph RAG model \n",
            "proposed in this paper shows obvious advantages in dealing \n",
            "with complex knowledge reasoning and generation tasks, and \n",
            "this method can be further optimized and applied in more \n",
            "practical scenarios in the future. \n",
            "REFERENCES \n",
            "[1] Y. Zi, X. Cheng, T. Mei, Q. Wang, Z. Gao and H. Yang, \n",
            "\"Research on Intelligent System of Medical Image Recognition \n",
            "and Disease Diagnosis Based on Big Data\", Proceedings of the \n",
            "2024 IEEE 2nd International Conference on Image Processing \n",
            "and Computer Applications (ICIPCA), pp. 825-830, 2024. \n",
            "[2] C. Mavromatis and G. Karypis, \"GNN -RAG: Graph Neural \n",
            "Retrieval for Large Language Model Reasoning,\" arXiv preprint \n",
            "arXiv:2405.20139, 2024. \n",
            "[3] G. Bénédict, R. Zhang, D. Metzler et al., \"Gen-IR@ SIGIR 2024: \n",
            "The Second Workshop on Generative Information Retrieval,\" \n",
            "Proceedings of the 47th International ACM SIGIR Conference \n",
            "on Research and Development in Information Retrieval, pp. \n",
            "3029-3032, 2024. \n",
            "[4] G. Huang, A. Shen, Y. Hu, J. Du, J. Hu and Y. Liang, \n",
            "\"Optimizing YOLOv5s Object Detection through Knowledge \n",
            "Distillation Algorithm\", arXiv preprint arXiv:2410.12259, 2024. \n",
            "[5] S. Duan, R. Zhang, M. Chen, Z. Wang and S. Wang, \"Efficient \n",
            "and Aesthetic UI Design with a Deep Learning -Based Interface \n",
            "Generation Tree Algorithm\", arXiv preprint arXiv:2410.17586, \n",
            "2024. \n",
            "[6] Y. Wu, K. Xu, H. Xia, B. Wang and N. Sang, \"Adaptive Feature \n",
            "Interaction Model for Credit Risk Prediction in the Digital \n",
            "Finance Landscape\", Journal of Computer Science and Software \n",
            "Applications, vol. 3, no. 1, pp. 31-38, 2023. \n",
            "[7] Y. Liang, X. Liu, H. Xia, Y. Cang, Z. Zheng and Y. Yang, \n",
            "\"Convolutional Neural Networks for Predictive Modeling of \n",
            "Lung Disease\", arXiv preprint arXiv:2408.12605, 2024. \n",
            "[8] M. Sui, J. Hu, T. Zhou, Z. Liu, L. Wen and J. Du, \"Deep \n",
            "Learning-Based Channel Squeeze U -Structure for Lung Nodule \n",
            "Detection and Segmentation\", arXiv preprint arXiv:2409.13868, \n",
            "2024. \n",
            "[9] K. Sawarkar, A. Mangal and S. R. Solanki, \"Blended RAG: \n",
            "Improving RAG (Retriever -Augmented Generation) Accuracy \n",
            "with Semantic Search and Hybrid Query -Based \n",
            "Retrievers,\" 2024 IEEE 7th International Conference on \n",
            "Multimedia Information Processing and Retrieval (MIPR) , pp. \n",
            "155-161, 2024. \n",
            "[10] X. Cheng, T. Mei, Y. Zi, Q. Wang, Z. Gao and H. Yang, \n",
            "\"Algorithm Research of ELMo Word Embedding and Deep \n",
            "Learning Multimodal Transformer in Image Description\", arXiv \n",
            "preprint arXiv:2408.06357, 2024. \n",
            "[11] B. Liu, I. Li, J. Yao, Y. Chen, G. Huang and J. Wang, \n",
            "\"Unveiling the Potential of Graph Neural Networks in SME \n",
            "Credit Risk Assessment\", arXiv preprint arXiv:2409.17909, \n",
            "2024. \n",
            "[12] H. Liu, B. Zhang, Y. Xiang, Y. Hu, A. Shen and Y. Lin, \n",
            "\"Adversarial Neural Networks in Medical Imaging: \n",
            "Advancements and Challenges in Semantic Segmentation\", \n",
            "arXiv preprint arXiv:2410.13099, 2024. \n",
            "[13] W. Wang, M. Gao, M. Xiao, X. Yan, and Y. Li, \"Breast cancer \n",
            "image classification method based on deep transfer learning\", \n",
            "arXiv preprint arXiv:2404.09226, 2024. \n",
            "[14] J. Du, Y. Jiang, S. Lyu and Y. Liang, \"Transformers in Opinion \n",
            "Mining: Addressing Semantic Complexity and Model \n",
            "Challenges in NLP\", Transactions on Computational and \n",
            "Scientific Methods, vol. 4, no. 10, 2024. \n",
            "[15] J. Wei, Y. Liu, X. Huang, X. Zhang, W. Liu and X. Yan, \"Self -\n",
            "Supervised Graph Neural Networks for Enhanced Feature \n",
            "Extraction in Heterogeneous Information Networks\", arXiv \n",
            "preprint arXiv:2410.17617, 2024. \n",
            "[16] W. Yang, Z. Wu, Z. Zheng, B. Zhang, S. Bo and Y. Yang, \n",
            "\"Dynamic Hypergraph -Enhanced Prediction of Sequential \n",
            "Medical Visits\", arXiv preprint arXiv:2408.07084, 2024. \n",
            "[17] W. Liu, R. Wang, Y. Luo, J. Wei, Z. Zhao and J. Huang, \"A \n",
            "Recommendation Model Utilizing Separation Embedding and \n",
            "Self-Attention for Feature Mining\", arXiv preprint \n",
            "arXiv:2410.15026, 2024. \n",
            "[18] Y. Cang, W. Yang, D. Sun, Z. Ye and Z. Zheng, \"ALBERT -\n",
            "Driven Ensemble Learning for Medical Text Classification\", \n",
            "Journal of Computer Technology and Software, vol. 3, no. 6, \n",
            "2024. \n",
            "[19] M. Jiang, J. Lin, H. Ouyang, J. Pan, S. Han and B. Liu, \n",
            "\"Wasserstein Distance -Weighted Adversarial Network for \n",
            "Cross-Domain Credit Risk Assessment\", arXiv preprint \n",
            "arXiv:2409.18544, 2024. \n",
            "[20] Z. Xu, J. Pan, S. Han, H. Ouyang, Y. Chen and M. Jiang, \n",
            "\"Predicting Liquidity Coverage Ratio with Gated Recurrent \n",
            "Units: A Deep Learning Model for Risk Management\", arXiv \n",
            "preprint arXiv:2410.19211, 2024. \n",
            "[21] X. Yan, Y. Jiang, W. Liu, D. Yi and J. Wei, \"Transforming \n",
            "Multidimensional Time Series into Interpretable Event \n",
            "Sequences for Advanced Data Mining\", arXiv preprint \n",
            "arXiv:2409.14327, 2024. \n",
            "[22] K. S. Kaswan, J. S. Dhatterwal, R. Batra and D. K. Yadav, \n",
            "\"ChatGPT: A Comprehensive Review of a Large Language \n",
            "Model,\" 2023 International Conference on Communication, \n",
            "Security and Artificial Intelligence (ICCSAI), pp. 738-743, 2023\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def pdfreaderload(path):\n",
        "  reader=PdfReader(path)\n",
        "  text=\"\"\n",
        "  for page in reader.pages:\n",
        "    text+=page.extract_text().rstrip()+\"\\n\"\n",
        "  return text\n",
        "\n",
        "\n",
        "path=\"/content/RAGG.pdf\"\n",
        "finaltext=pdfreaderload(path)\n",
        "print(finaltext)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gihfrQ7sxkEy",
        "outputId": "a12d5584-4138-46fa-b717-f8e6354c57b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27902\n"
          ]
        }
      ],
      "source": [
        "print(len(finaltext))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cEgiy5wnx5R0"
      },
      "outputs": [],
      "source": [
        "import unicodedata\n",
        "\n",
        "# NFKD = Normalization Form Compatibility Decomposition\n",
        "def normalize_unicode(text):\n",
        "    return unicodedata.normalize(\"NFKD\", text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5_P7HbYY1VYQ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def remove_extra_whitespace(text):\n",
        "    # Remove multiple blank lines\n",
        "    text = re.sub(r'\\n\\s*\\n+', '\\n\\n', text)\n",
        "    return text.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBLcRRcJ1WO8",
        "outputId": "1119451c-fb1b-47be-ba68-456d5908f4c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Advanced RAG Models with Graph Structures: Optimizing Complex Knowledge Reasoning and Text Generation                                                    Abstract—This study aims to optimize the existing retrieval-augmented generation model (RAG) by introducing a graph structure to improve the performance of the model in dealing with complex knowledge reasoning tasks. The traditional RAG model has the problem of insufficient processing efficiency when facing complex graph structure information (such as knowledge graphs, hierarchical relationships, etc.), which affects the quality and consistency of the generated results. This study proposes a scheme to process graph structure data by combining graph neural network (GNN), so that the model can capture the complex relationship between entities, thereby improving the knowledge consistency and reasoning ability of the generated text. The experiment used the Natural Questions (NQ) dataset and compared it with multiple existing generation models. The results show that the graph-based RAG model proposed in this paper is superior to the traditional generation model in terms of quality, knowledge consistency , and reasoning ability, especially when dealing with tasks that require multi -dimensional reasoning. Through the combination of the enhancement of the retrieval module and the graph neural network, the model in this study can better handle complex knowledge background information and has broad potential value in multiple practical application scenarios. Keywords-Graph neural network, retrieval -enhanced generation, knowledge consistency, reasoning ability I.  INTRODUCTION  At present, generative models have shown great potential in many application fields  [1]. However, traditional generative language models mainly rely on a large amount of pre -trained data for learning. Although these models can generate relatively coherent text, their generation ability is still limited when facing external knowledge or complex background information. To this end, the retrieval -augmented generation model (RAG) came into being. By combining the retrieval system with the generation model, it can dynamically access external knowledge during the generation process, thereby greatly improving the quality and accuracy of generation. Especially in tasks that require a rich knowledge background or complex reasoning, the RAG model shows stronger advantages than the single-generation model [2]. However, the existing RAG model still has certain limitations [3]. First, the retrieval module of the RAG model is usually text-based, which means that it is difficult to effectively process complex structured information (such as graph structure [4], hierarchical relationship  [5], etc.). In practical applications, a lot of knowledge has inherent structured characteristics, especially in scenarios such as knowledge graphs [6], social networks, scientific literature, etc., where information is not just discrete text fragments, but has a high degree of association and contextual relationship [7-8]. Faced with this complex graph structure information, traditional RAG models are often difficult to fully utilize, thus affecting the generation effect. Secondly, the synergy between the retrieval module and the generation module still needs to be further optimized. Although the current RAG model can use external information to enhance the generation effect, it still has inaccurate or incoherent generation results when dealing with complex reasoning tasks, which limits its application in some high-demand scenarios [9]. In order to solve the above problems, the RAG model combined with graph structure has gradually become a hot topic of research. Graph structure data can express the complex relationship between different objects in the form of nodes and edges, so it is widely used in many fields , such as knowledge graphs [10], financial networks [11], and medical analysis.[12]. By introducing technologies such as graph neural networks (GNNs), RAG models can better process structured knowledge and extract valuable information from them for the generation process. For example, in the knowledge graph, each node represents an entity and the edge represents the relationship between entities. The graph neural network can effectively capture this association structure, so that the model can access Yu x in DongWake Forest UniversityWinston-Salem, USAShuo WangPurdue UniversityIndianapolis, USAHongye ZhengThe Chinese University of Hong Kong Hong Kong, ChinaChihang Wang *New Yo rk UniversityNew Yo rk, USAZhenhong ZhangGeorge Washington University Washington, USA���������������������������������������������richer contextual information when generating. This RAG model combined with graph structure can better cope with complex knowledge reasoning tasks and significantly improve the generation quality and rationality of the model. In practical applications, the RAG model based on graph structure has a wide range of potential values. In the medical field, the graph RAG model can be used for medical record generation and diagnosis assistance. Medical records usually contain a variety of structured information such as the patient's historical condition, diagnosis, and treatment plan. The graph -based model can better handle the association between this information and generate reports or suggestions with diagnostic value [13]. In short, the optimization and application research of the graph -based retrieval enhancement generation model RAG has important practical significance and broad application prospects. By introducing graph structure information, the RAG model can demonstrate stronger expressiveness in processing complex knowledge reasoning and generation tasks. At the same time, with the continuous development of technologies such as graph neural networks, the graph RAG model will also usher in more optimization and application opportunities in the future, providing technical support for intelligent generation in more fields. II. RELATED WORK This study enhances the Retrieval -Augmented Generation (RAG) model by incorporating graph structures through Graph Neural Networks (GNNs) to support complex reasoning and improve generation quality. Prior research has informed various aspects of this work, from foundational NLP improvements to methodologies for structuring and processing complex, interconnected data. A central component of the RAG model is the transformer architecture, which has been instrumental in handling semantic complexity. Du et al. [14] discuss transformers' applications in managing intricate semantic information in natural language processing (NLP), highlighting the mechanisms that allow models to capture nuanced relationships within text. Such advancements are directly relevant to this study’s aim to process complex graph structures within RAG models, enhancing retrieval capabilities and accuracy in text generation. Several studies have contributed to understanding structured knowledge processing through GNNs and other embedding techniques. Wei et al. [15] propose a self -supervised GNN model that improves feature extraction across heterogeneous information networks, a methodology closely aligned with this paper's approach. Their techniques provide a foundation for integrating GNNs in RAG models, improving the model’s ability to understand complex associations within structured knowledge, such as in knowledge graphs. Similarly, Yang et al. [16] demonstrated the potential of dynamic hypergraphs in managing sequences and associations within data, supporting the notion that graph -enhanced models can effectively capture interconnected information within knowledge-rich domains. The model's retrieval module benefits from embedding strategies and attention mechanisms for feature enhancement, as highlighted by Liu et al. [17]. Their work on using separation embedding and self -attention strengthens understanding of how embeddings can improve interpretability and contextual sensitivity, both crucial for this paper’s RAG model in ensuring knowledge consistency and coherence. Cang et al. [18] also explore ensemble methods with transformer -based models to handle specialized datasets, providing insight into techniques for augmenting model adaptability when working with structured, domain-specific information. Another relevant contribution involves approaches for model optimization and improved robustness in handling structured data. Jiang et al. [19] developed a weighted adversarial network to enhance cross -domain consistency, a concept that aligns with the present study’s objective to improve the accuracy and reliability of generated responses when handling multifaceted knowledge. Additionally, Xu et al. [20] applied deep learning architectures to predict sequential and temporally linked information, exemplifying effective strategies for embedding temporal relationships that mirror the graph structure's role in maintaining logical flow within generated text. Moreover, the integration of interpretable data transformations, such as Yan et al.’s [21] transformation of multidimensional time series into interpretable sequences, underscores the value of structured data processing. These methods inform this study’s approach to embedding graph structures in the RAG model to improve interpretability and coherence across generated content, particularly for complex reasoning tasks. III. METHOD  In this study, we proposed a graph-based retrieval-enhanced generation model (RAG) optimization scheme, and combined it with a graph neural network (GNN) to process graph structure information, thereby improving the model's generation ability in complex scenarios. To achieve this goal, our model framework mainly consists of three parts: graph structure processing module, retrieval module, and generation module as shown in Figure 1.  Figure 1 Graph network architecture First, in the graph structure processing module, a graph neural network is used to encode the graph structure data. Assume that a graph structure can be represented as ),( EVG =, where V is a set of nodes and E is a set of edges. Each node Vv   represents an entity or object, and edge ),( ji vve = represents the relationship between nodes iv  and jv. For each node, we first represent its initial feature as 0ih  and then update the representation of each node through the propagation mechanism of the graph neural network. The basic propagation mechanism of graph neural networks can be defined as: ))})(:({( )()()()1( kkjkki biNjhAGGWh +=+   Among them, )(iN  represents the set of neighbor nodes of node iv , AGG is the aggregation function, common aggregation methods include average, sum or maximum, )(  is the nonlinear activation function, )(kW and )(kb are the weight matrix and bias term of the kth layer respectively. After multiple layers of propagation and updating, we can get the final representation )(Lih  of each node, where L is the number of layers of the graph neural network.  Next, in the retrieval module, we perform retrieval in combination with graph structure information. In order to improve retrieval efficiency, we adopt a retrieval method based on graph embedding. Suppose we have a knowledge base K, which contains multiple knowledge fragments, each of which can be represented by a graph structure as kG . We first perform graph encoding on each kG  to obtain the embedding vector kz  of each knowledge fragment. Then, for the input query, we also generate the graph embedding vector qz  of the query through the graph neural network, and calculate the similarity between the query and each knowledge fragment in the knowledge base through the similarity between the vectors (cosine similarity): ||||||||),(kqkqkqzzzzzzsim = The knowledge fragments with the highest similarity will be retrieved as the input of the generation module. This graph -based retrieval method can more effectively capture complex entity relationships and improve the accuracy of retrieval. Finally, in the generation module, we use a generation model based on Chatgpt4.0 to generate text. Assuming that the retrieval module returns relevant knowledge fragments, each knowledge fragment is represented as a vector, we embed these retrieved knowledge fragments and input the query into the generation model together. During the generation process, the generation model will dynamically adjust the generation strategy according to the relevant information of these knowledge fragments to improve the relevance and accuracy of the generation results. Specifically, the goal of the generation process is to maximize the conditional probability ),...,,,|( 21 NzzzqyPgiven a queryq and retrieved knowledge fragment Nzzz ,...,, 21 , where y  represents the generated target text. This conditional probability can be represented by the output distribution of the generation model: )max(),...,,,,|( 21 otoNtt bhWsoftzzzqyyP += Among them, ty  represents the t -th word generated,ty  represents the first t -1 words generated, th is the hidden state of the generative model at time step t, and oW  and ob  are the parameters of the output layer. By continuously generating the next word until the generation end mark is reached, the model can complete the generation of the entire text. In summary, this method introduces graph neural networks to process graph structured data and combines it with a retrieval-enhanced generation model to effectively utilize external knowledge in the generation process, thereby achieving better generation effects for complex knowledge scenarios. IV. EXPERIMENT A. Introduction to the dataset and the LLM used In this experiment, we used a generative model based on ChatGPT-4 as the core part of the experiment. ChatGPT -4 is a large-scale pre-trained language model developed by OpenAI. It is based on the Transformer architecture and can generate natural and coherent text [22]. ChatGPT-4 has strong language understanding and generation capabilities and can handle a wide range of text -generation tasks. However, in order to further improve the performance in knowledge -intensive and reasoning tasks, we combined the design of the RAG (Retrieval Augmented Generation) model to dynamically obtain relevant information from external knowledge bases through the retrieval module to generate more knowledge -accurate and relevant answers. This architecture can effectively make up for the problem that the generative model relies solely on training data, enabling it to handle knowledge reasoning and complex tasks in more fields. In our experiments, we used the Natural Questions (NQ) dataset, which is widely used for retrieval and generation tasks. NQ is an open-domain question-answering dataset that contains real question queries from users, accompanied by relevant document snippets automatically retrieved from Internet resources such as Wikipedia. Each data sample consists of a query, a retrieved document, and an answer, covering a wide range of content in multiple fields such as history, science, and culture. The diversity of the NQ dataset makes it an ideal choice for evaluating the performance and reasoning ability of generative models on complex domain problems. This experiment uses this dataset to test the retrieval and generation capabilities of our model to evaluate the accuracy and knowledge completeness of its generated text. This experiment is run in a high -performance computing environment. The experimental hardware configuration includes NVIDIA A100 GPU, 128GB memory and 64 -core CPU, which can support efficient training and reasoning of large-scale models. The experimental software is mainly based on the PyTorch framework for model training and evaluation, and combines Hugging Face's Transformers library to implement the retrieval and generation functions of the RAG model. B. Experimental Results We will select five different generative models to conduct comparative experiments with the RAG model based on graph structure optimization proposed in this paper (labeled as Ours). By comparing their performance on the same dataset, we can verify the superiority of our model. The evaluation indicators used in the comparative experiments include Quality, Knowledge Consistency (KC), and Reasoning Capability(RC). Table 1 Experimental Results Model Quality KC RC BART 0.74 0.65 0.68 T5 0.78 0.68 0.72 RAG 0.82 0.73 0.80 RAG+T 0.85 0.76 0.84 FID 0.87 0.78 0.87 ours 0.90 0.85 0.91  From the experimental results as shown in Table 1, the performance of each model in the three indicators of Quality, Knowledge Consistency, and Reasoning Capability varies. It can be observed that traditional generative models such as BART and T5 performed relatively weakly in the experiment, especially in terms of knowledge consistency and reasoning capability. BART's quality score is 0.74, KC score is 0.65, and reasoning capability is 0.68, reflecting that although its generated text is fluent, it cannot provide sufficient external support in knowledge -intensive tasks. The T5 model has a slight improvement in the three indicators, especially in reasoning capability (0.72), which shows that the T5 model can improve its generalization ability by unifying task processing, but it is still not enough to fully handle complex knowledge reasoning tasks. In contrast, the RAG model and its improved version RAG+T (RAG+Text) perform significantly better than BART and T5 in these three indicators. The RAG model combines the retrieval module to enable it to dynamically access the external knowledge base during the generation process, thereby significantly improving knowledge consistency (0.73) and reasoning capability (0.80). The performance of RAG+T is further improved, especially in terms of reasoning ability, which reaches 0.84, which shows the great potential of retrieval-enhanced generative models in complex tasks. By incorporating more relevant knowledge into the generation process, RAG+T shows stronger ability to deal with complex background information and deep reasoning, further narrowing the limitations of generative models in dealing with knowledge-intensive tasks. Finally, the graph -based RAG optimization model (ours) proposed in this paper performs well in all indicators, with a quality score of 0.90, knowledge consistency of 0.85, and reasoning ability of 0.91, which is significantly better than other models. This result verifies the effectiveness of our introduction of graph structure information. The graph neural network can capture the complex relationship between nodes and edges in the data, enabling the model to better handle complex knowledge reasoning tasks during the generation process and generate text with higher knowledge consistency. In addition, our model performs particularly well in reasoning ability, showing that when faced with complex problems, the retrieval-enhanced model combined with the graph structure can generate answers more accurately, indicating that the graph RAG model has significant advantages in dealing with generation tasks with structured knowledge. Overall, our model not only improves the generation quality, but also greatly improves the knowledge accuracy and reasoning depth of the generated text while maintaining a high generation speed. At the same time, we also let the model perform generation tasks under the conditions of retrieving 1, 3, 5, and 10 documents to observe the performance of the model under different document scales. Table 2  Experimental results of different document sizes Number of documents Quality KC RC 1 0.83 0.81 0.82 3 0.87 0.83 0.88 5 0.89 0.85 0.90 10 0.89 0.85 0.91  From the experimental results in Table 2, it can be seen that with the increase in the number of retrieved documents, the quality, knowledge -KC, and RC of the model have all been significantly improved, but after the number of documents increases to a certain extent, this improvement tends to be flat. When retrieving 1 document, the quality, knowledge consistency, and reasoning ability of the model are 0.83, 0.81, and 0.82, respectively. This shows that although a single document can provide some effective information, due to the limitation of the amount of information, the model is weak in complex reasoning and knowledge integration, and the generated results are limited. As the number of documents increases to 3, the model has been significantly improved in all indicators, with the quality reaching 0.87 and the reasoning ability also increased to 0.88. This shows that more documents can provide a richer source of knowledge, significantly enhancing the reasoning depth and knowledge consistency of the model. When the number of documents increases to 5, the model performs best, with quality, knowledge consistency, and reasoning ability of 0.89, 0.85, and 0.90, respectively, showing the best balance effect. However, when the number of documents further increased to 10, the model's reasoning ability slightly improved to 0.91, but the quality and knowledge consistency did not improve further, remaining at 0.89 and 0.85. This shows that too many documents will lead to information redundancy, resulting in the model being unable to effectively utilize these additional knowledge fragments, and the gain is limited. V. CONCLUSION The retrieval-augmented generation model (RAG) based on graph structure optimization proposed in this study introduces graph neural network (GNN) to process structured graph data, which significantly improves the performance of the model in complex reasoning tasks. Experimental results show that the RAG model combined with graph structure information is superior to traditional generation models in terms of generation quality, knowledge consistency and reasoning ability, especially when dealing with multi -document retrieval. When the number of document retrieval is moderate, the model can effectively utilize the external knowledge base to achieve higher quality generated text, and perform well in reasoning tasks with complex background information. Although increasing the number of retrieved documents can improve the reasoning ability of the model to a certain extent, when the number of documents is too large, information redundancy will affect the generation quality and knowledge consistency, and the gain effect is limited. This shows that there is an optimal balance point for the amount of information retrieved, and beyond this point, the performance improvement of the model tends to be flat. Overall, the graph RAG model proposed in this paper shows obvious advantages in dealing with complex knowledge reasoning and generation tasks, and this method can be further optimized and applied in more practical scenarios in the future. REFERENCES [1] Y. Zi, X. Cheng, T. Mei, Q. Wang, Z. Gao and H. Yang, \"Research on Intelligent System of Medical Image Recognition and Disease Diagnosis Based on Big Data\", Proceedings of the 2024 IEEE 2nd International Conference on Image Processing and Computer Applications (ICIPCA), pp. 825-830, 2024. [2] C. Mavromatis and G. Karypis, \"GNN -RAG: Graph Neural Retrieval for Large Language Model Reasoning,\" arXiv preprint arXiv:2405.20139, 2024. [3] G. Bénédict, R. Zhang, D. Metzler et al., \"Gen-IR@ SIGIR 2024: The Second Workshop on Generative Information Retrieval,\" Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 3029-3032, 2024. [4] G. Huang, A. Shen, Y. Hu, J. Du, J. Hu and Y. Liang, \"Optimizing YOLOv5s Object Detection through Knowledge Distillation Algorithm\", arXiv preprint arXiv:2410.12259, 2024. [5] S. Duan, R. Zhang, M. Chen, Z. Wang and S. Wang, \"Efficient and Aesthetic UI Design with a Deep Learning -Based Interface Generation Tree Algorithm\", arXiv preprint arXiv:2410.17586, 2024. [6] Y. Wu, K. Xu, H. Xia, B. Wang and N. Sang, \"Adaptive Feature Interaction Model for Credit Risk Prediction in the Digital Finance Landscape\", Journal of Computer Science and Software Applications, vol. 3, no. 1, pp. 31-38, 2023. [7] Y. Liang, X. Liu, H. Xia, Y. Cang, Z. Zheng and Y. Yang, \"Convolutional Neural Networks for Predictive Modeling of Lung Disease\", arXiv preprint arXiv:2408.12605, 2024. [8] M. Sui, J. Hu, T. Zhou, Z. Liu, L. Wen and J. Du, \"Deep Learning-Based Channel Squeeze U -Structure for Lung Nodule Detection and Segmentation\", arXiv preprint arXiv:2409.13868, 2024. [9] K. Sawarkar, A. Mangal and S. R. Solanki, \"Blended RAG: Improving RAG (Retriever -Augmented Generation) Accuracy with Semantic Search and Hybrid Query -Based Retrievers,\" 2024 IEEE 7th International Conference on Multimedia Information Processing and Retrieval (MIPR) , pp. 155-161, 2024. [10] X. Cheng, T. Mei, Y. Zi, Q. Wang, Z. Gao and H. Yang, \"Algorithm Research of ELMo Word Embedding and Deep Learning Multimodal Transformer in Image Description\", arXiv preprint arXiv:2408.06357, 2024. [11] B. Liu, I. Li, J. Yao, Y. Chen, G. Huang and J. Wang, \"Unveiling the Potential of Graph Neural Networks in SME Credit Risk Assessment\", arXiv preprint arXiv:2409.17909, 2024. [12] H. Liu, B. Zhang, Y. Xiang, Y. Hu, A. Shen and Y. Lin, \"Adversarial Neural Networks in Medical Imaging: Advancements and Challenges in Semantic Segmentation\", arXiv preprint arXiv:2410.13099, 2024. [13] W. Wang, M. Gao, M. Xiao, X. Yan, and Y. Li, \"Breast cancer image classification method based on deep transfer learning\", arXiv preprint arXiv:2404.09226, 2024. [14] J. Du, Y. Jiang, S. Lyu and Y. Liang, \"Transformers in Opinion Mining: Addressing Semantic Complexity and Model Challenges in NLP\", Transactions on Computational and Scientific Methods, vol. 4, no. 10, 2024. [15] J. Wei, Y. Liu, X. Huang, X. Zhang, W. Liu and X. Yan, \"Self -Supervised Graph Neural Networks for Enhanced Feature Extraction in Heterogeneous Information Networks\", arXiv preprint arXiv:2410.17617, 2024. [16] W. Yang, Z. Wu, Z. Zheng, B. Zhang, S. Bo and Y. Yang, \"Dynamic Hypergraph -Enhanced Prediction of Sequential Medical Visits\", arXiv preprint arXiv:2408.07084, 2024. [17] W. Liu, R. Wang, Y. Luo, J. Wei, Z. Zhao and J. Huang, \"A Recommendation Model Utilizing Separation Embedding and Self-Attention for Feature Mining\", arXiv preprint arXiv:2410.15026, 2024. [18] Y. Cang, W. Yang, D. Sun, Z. Ye and Z. Zheng, \"ALBERT -Driven Ensemble Learning for Medical Text Classification\", Journal of Computer Technology and Software, vol. 3, no. 6, 2024. [19] M. Jiang, J. Lin, H. Ouyang, J. Pan, S. Han and B. Liu, \"Wasserstein Distance -Weighted Adversarial Network for Cross-Domain Credit Risk Assessment\", arXiv preprint arXiv:2409.18544, 2024. [20] Z. Xu, J. Pan, S. Han, H. Ouyang, Y. Chen and M. Jiang, \"Predicting Liquidity Coverage Ratio with Gated Recurrent Units: A Deep Learning Model for Risk Management\", arXiv preprint arXiv:2410.19211, 2024. [21] X. Yan, Y. Jiang, W. Liu, D. Yi and J. Wei, \"Transforming Multidimensional Time Series into Interpretable Event Sequences for Advanced Data Mining\", arXiv preprint arXiv:2409.14327, 2024. [22] K. S. Kaswan, J. S. Dhatterwal, R. Batra and D. K. Yadav, \"ChatGPT: A Comprehensive Review of a Large Language Model,\" 2023 International Conference on Communication, Security and Artificial Intelligence (ICCSAI), pp. 738-743, 2023\n"
          ]
        }
      ],
      "source": [
        "from pypdf import PdfReader\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "def load_and_clean_pdf(path):\n",
        "    reader = PdfReader(path)\n",
        "    text = \"\"\n",
        "\n",
        "    for page in reader.pages:\n",
        "        page_text = page.extract_text()\n",
        "        if page_text:\n",
        "            text += page_text + \"\\n\"\n",
        "\n",
        "    # Normalize unicode\n",
        "    text = unicodedata.normalize(\"NFKD\", text)\n",
        "\n",
        "    # Remove non-printable characters\n",
        "    text = ''.join(c for c in text if c.isprintable())\n",
        "\n",
        "    # Collapse excessive blank lines\n",
        "    text = re.sub(r'\\n\\s*\\n+', '\\n\\n', text)\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "finaltext = load_and_clean_pdf(\"/content/RAGG.pdf\")\n",
        "print(finaltext)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlDYzm9q1rnQ",
        "outputId": "8648948f-a99c-414f-dfd0-cba410e566ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45\n"
          ]
        }
      ],
      "source": [
        "print(finaltext.count(\"�\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9kxpB6vM2f2G"
      },
      "outputs": [],
      "source": [
        "def remove_replacement_chars(text):\n",
        "    return text.replace(\"�\", \"\")\n",
        "finaltext=remove_replacement_chars(finaltext)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ6TIXQi2j9k",
        "outputId": "f5a9243e-730d-43ff-9498-a1acac53059c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Advanced RAG Models with Graph Structures: Optimizing Complex Knowledge Reasoning and Text Generation                                                    Abstract—This study aims to optimize the existing retrieval-augmented generation model (RAG) by introducing a graph structure to improve the performance of the model in dealing with complex knowledge reasoning tasks. The traditional RAG model has the problem of insufficient processing efficiency when facing complex graph structure information (such as knowledge graphs, hierarchical relationships, etc.), which affects the quality and consistency of the generated results. This study proposes a scheme to process graph structure data by combining graph neural network (GNN), so that the model can capture the complex relationship between entities, thereby improving the knowledge consistency and reasoning ability of the generated text. The experiment used the Natural Questions (NQ) dataset and compared it with multiple existing generation models. The results show that the graph-based RAG model proposed in this paper is superior to the traditional generation model in terms of quality, knowledge consistency , and reasoning ability, especially when dealing with tasks that require multi -dimensional reasoning. Through the combination of the enhancement of the retrieval module and the graph neural network, the model in this study can better handle complex knowledge background information and has broad potential value in multiple practical application scenarios. Keywords-Graph neural network, retrieval -enhanced generation, knowledge consistency, reasoning ability I.  INTRODUCTION  At present, generative models have shown great potential in many application fields  [1]. However, traditional generative language models mainly rely on a large amount of pre -trained data for learning. Although these models can generate relatively coherent text, their generation ability is still limited when facing external knowledge or complex background information. To this end, the retrieval -augmented generation model (RAG) came into being. By combining the retrieval system with the generation model, it can dynamically access external knowledge during the generation process, thereby greatly improving the quality and accuracy of generation. Especially in tasks that require a rich knowledge background or complex reasoning, the RAG model shows stronger advantages than the single-generation model [2]. However, the existing RAG model still has certain limitations [3]. First, the retrieval module of the RAG model is usually text-based, which means that it is difficult to effectively process complex structured information (such as graph structure [4], hierarchical relationship  [5], etc.). In practical applications, a lot of knowledge has inherent structured characteristics, especially in scenarios such as knowledge graphs [6], social networks, scientific literature, etc., where information is not just discrete text fragments, but has a high degree of association and contextual relationship [7-8]. Faced with this complex graph structure information, traditional RAG models are often difficult to fully utilize, thus affecting the generation effect. Secondly, the synergy between the retrieval module and the generation module still needs to be further optimized. Although the current RAG model can use external information to enhance the generation effect, it still has inaccurate or incoherent generation results when dealing with complex reasoning tasks, which limits its application in some high-demand scenarios [9]. In order to solve the above problems, the RAG model combined with graph structure has gradually become a hot topic of research. Graph structure data can express the complex relationship between different objects in the form of nodes and edges, so it is widely used in many fields , such as knowledge graphs [10], financial networks [11], and medical analysis.[12]. By introducing technologies such as graph neural networks (GNNs), RAG models can better process structured knowledge and extract valuable information from them for the generation process. For example, in the knowledge graph, each node represents an entity and the edge represents the relationship between entities. The graph neural network can effectively capture this association structure, so that the model can access Yu x in DongWake Forest UniversityWinston-Salem, USAShuo WangPurdue UniversityIndianapolis, USAHongye ZhengThe Chinese University of Hong Kong Hong Kong, ChinaChihang Wang *New Yo rk UniversityNew Yo rk, USAZhenhong ZhangGeorge Washington University Washington, USAricher contextual information when generating. This RAG model combined with graph structure can better cope with complex knowledge reasoning tasks and significantly improve the generation quality and rationality of the model. In practical applications, the RAG model based on graph structure has a wide range of potential values. In the medical field, the graph RAG model can be used for medical record generation and diagnosis assistance. Medical records usually contain a variety of structured information such as the patient's historical condition, diagnosis, and treatment plan. The graph -based model can better handle the association between this information and generate reports or suggestions with diagnostic value [13]. In short, the optimization and application research of the graph -based retrieval enhancement generation model RAG has important practical significance and broad application prospects. By introducing graph structure information, the RAG model can demonstrate stronger expressiveness in processing complex knowledge reasoning and generation tasks. At the same time, with the continuous development of technologies such as graph neural networks, the graph RAG model will also usher in more optimization and application opportunities in the future, providing technical support for intelligent generation in more fields. II. RELATED WORK This study enhances the Retrieval -Augmented Generation (RAG) model by incorporating graph structures through Graph Neural Networks (GNNs) to support complex reasoning and improve generation quality. Prior research has informed various aspects of this work, from foundational NLP improvements to methodologies for structuring and processing complex, interconnected data. A central component of the RAG model is the transformer architecture, which has been instrumental in handling semantic complexity. Du et al. [14] discuss transformers' applications in managing intricate semantic information in natural language processing (NLP), highlighting the mechanisms that allow models to capture nuanced relationships within text. Such advancements are directly relevant to this study’s aim to process complex graph structures within RAG models, enhancing retrieval capabilities and accuracy in text generation. Several studies have contributed to understanding structured knowledge processing through GNNs and other embedding techniques. Wei et al. [15] propose a self -supervised GNN model that improves feature extraction across heterogeneous information networks, a methodology closely aligned with this paper's approach. Their techniques provide a foundation for integrating GNNs in RAG models, improving the model’s ability to understand complex associations within structured knowledge, such as in knowledge graphs. Similarly, Yang et al. [16] demonstrated the potential of dynamic hypergraphs in managing sequences and associations within data, supporting the notion that graph -enhanced models can effectively capture interconnected information within knowledge-rich domains. The model's retrieval module benefits from embedding strategies and attention mechanisms for feature enhancement, as highlighted by Liu et al. [17]. Their work on using separation embedding and self -attention strengthens understanding of how embeddings can improve interpretability and contextual sensitivity, both crucial for this paper’s RAG model in ensuring knowledge consistency and coherence. Cang et al. [18] also explore ensemble methods with transformer -based models to handle specialized datasets, providing insight into techniques for augmenting model adaptability when working with structured, domain-specific information. Another relevant contribution involves approaches for model optimization and improved robustness in handling structured data. Jiang et al. [19] developed a weighted adversarial network to enhance cross -domain consistency, a concept that aligns with the present study’s objective to improve the accuracy and reliability of generated responses when handling multifaceted knowledge. Additionally, Xu et al. [20] applied deep learning architectures to predict sequential and temporally linked information, exemplifying effective strategies for embedding temporal relationships that mirror the graph structure's role in maintaining logical flow within generated text. Moreover, the integration of interpretable data transformations, such as Yan et al.’s [21] transformation of multidimensional time series into interpretable sequences, underscores the value of structured data processing. These methods inform this study’s approach to embedding graph structures in the RAG model to improve interpretability and coherence across generated content, particularly for complex reasoning tasks. III. METHOD  In this study, we proposed a graph-based retrieval-enhanced generation model (RAG) optimization scheme, and combined it with a graph neural network (GNN) to process graph structure information, thereby improving the model's generation ability in complex scenarios. To achieve this goal, our model framework mainly consists of three parts: graph structure processing module, retrieval module, and generation module as shown in Figure 1.  Figure 1 Graph network architecture First, in the graph structure processing module, a graph neural network is used to encode the graph structure data. Assume that a graph structure can be represented as ),( EVG =, where V is a set of nodes and E is a set of edges. Each node Vv   represents an entity or object, and edge ),( ji vve = represents the relationship between nodes iv  and jv. For each node, we first represent its initial feature as 0ih  and then update the representation of each node through the propagation mechanism of the graph neural network. The basic propagation mechanism of graph neural networks can be defined as: ))})(:({( )()()()1( kkjkki biNjhAGGWh +=+   Among them, )(iN  represents the set of neighbor nodes of node iv , AGG is the aggregation function, common aggregation methods include average, sum or maximum, )(  is the nonlinear activation function, )(kW and )(kb are the weight matrix and bias term of the kth layer respectively. After multiple layers of propagation and updating, we can get the final representation )(Lih  of each node, where L is the number of layers of the graph neural network.  Next, in the retrieval module, we perform retrieval in combination with graph structure information. In order to improve retrieval efficiency, we adopt a retrieval method based on graph embedding. Suppose we have a knowledge base K, which contains multiple knowledge fragments, each of which can be represented by a graph structure as kG . We first perform graph encoding on each kG  to obtain the embedding vector kz  of each knowledge fragment. Then, for the input query, we also generate the graph embedding vector qz  of the query through the graph neural network, and calculate the similarity between the query and each knowledge fragment in the knowledge base through the similarity between the vectors (cosine similarity): ||||||||),(kqkqkqzzzzzzsim = The knowledge fragments with the highest similarity will be retrieved as the input of the generation module. This graph -based retrieval method can more effectively capture complex entity relationships and improve the accuracy of retrieval. Finally, in the generation module, we use a generation model based on Chatgpt4.0 to generate text. Assuming that the retrieval module returns relevant knowledge fragments, each knowledge fragment is represented as a vector, we embed these retrieved knowledge fragments and input the query into the generation model together. During the generation process, the generation model will dynamically adjust the generation strategy according to the relevant information of these knowledge fragments to improve the relevance and accuracy of the generation results. Specifically, the goal of the generation process is to maximize the conditional probability ),...,,,|( 21 NzzzqyPgiven a queryq and retrieved knowledge fragment Nzzz ,...,, 21 , where y  represents the generated target text. This conditional probability can be represented by the output distribution of the generation model: )max(),...,,,,|( 21 otoNtt bhWsoftzzzqyyP += Among them, ty  represents the t -th word generated,ty  represents the first t -1 words generated, th is the hidden state of the generative model at time step t, and oW  and ob  are the parameters of the output layer. By continuously generating the next word until the generation end mark is reached, the model can complete the generation of the entire text. In summary, this method introduces graph neural networks to process graph structured data and combines it with a retrieval-enhanced generation model to effectively utilize external knowledge in the generation process, thereby achieving better generation effects for complex knowledge scenarios. IV. EXPERIMENT A. Introduction to the dataset and the LLM used In this experiment, we used a generative model based on ChatGPT-4 as the core part of the experiment. ChatGPT -4 is a large-scale pre-trained language model developed by OpenAI. It is based on the Transformer architecture and can generate natural and coherent text [22]. ChatGPT-4 has strong language understanding and generation capabilities and can handle a wide range of text -generation tasks. However, in order to further improve the performance in knowledge -intensive and reasoning tasks, we combined the design of the RAG (Retrieval Augmented Generation) model to dynamically obtain relevant information from external knowledge bases through the retrieval module to generate more knowledge -accurate and relevant answers. This architecture can effectively make up for the problem that the generative model relies solely on training data, enabling it to handle knowledge reasoning and complex tasks in more fields. In our experiments, we used the Natural Questions (NQ) dataset, which is widely used for retrieval and generation tasks. NQ is an open-domain question-answering dataset that contains real question queries from users, accompanied by relevant document snippets automatically retrieved from Internet resources such as Wikipedia. Each data sample consists of a query, a retrieved document, and an answer, covering a wide range of content in multiple fields such as history, science, and culture. The diversity of the NQ dataset makes it an ideal choice for evaluating the performance and reasoning ability of generative models on complex domain problems. This experiment uses this dataset to test the retrieval and generation capabilities of our model to evaluate the accuracy and knowledge completeness of its generated text. This experiment is run in a high -performance computing environment. The experimental hardware configuration includes NVIDIA A100 GPU, 128GB memory and 64 -core CPU, which can support efficient training and reasoning of large-scale models. The experimental software is mainly based on the PyTorch framework for model training and evaluation, and combines Hugging Face's Transformers library to implement the retrieval and generation functions of the RAG model. B. Experimental Results We will select five different generative models to conduct comparative experiments with the RAG model based on graph structure optimization proposed in this paper (labeled as Ours). By comparing their performance on the same dataset, we can verify the superiority of our model. The evaluation indicators used in the comparative experiments include Quality, Knowledge Consistency (KC), and Reasoning Capability(RC). Table 1 Experimental Results Model Quality KC RC BART 0.74 0.65 0.68 T5 0.78 0.68 0.72 RAG 0.82 0.73 0.80 RAG+T 0.85 0.76 0.84 FID 0.87 0.78 0.87 ours 0.90 0.85 0.91  From the experimental results as shown in Table 1, the performance of each model in the three indicators of Quality, Knowledge Consistency, and Reasoning Capability varies. It can be observed that traditional generative models such as BART and T5 performed relatively weakly in the experiment, especially in terms of knowledge consistency and reasoning capability. BART's quality score is 0.74, KC score is 0.65, and reasoning capability is 0.68, reflecting that although its generated text is fluent, it cannot provide sufficient external support in knowledge -intensive tasks. The T5 model has a slight improvement in the three indicators, especially in reasoning capability (0.72), which shows that the T5 model can improve its generalization ability by unifying task processing, but it is still not enough to fully handle complex knowledge reasoning tasks. In contrast, the RAG model and its improved version RAG+T (RAG+Text) perform significantly better than BART and T5 in these three indicators. The RAG model combines the retrieval module to enable it to dynamically access the external knowledge base during the generation process, thereby significantly improving knowledge consistency (0.73) and reasoning capability (0.80). The performance of RAG+T is further improved, especially in terms of reasoning ability, which reaches 0.84, which shows the great potential of retrieval-enhanced generative models in complex tasks. By incorporating more relevant knowledge into the generation process, RAG+T shows stronger ability to deal with complex background information and deep reasoning, further narrowing the limitations of generative models in dealing with knowledge-intensive tasks. Finally, the graph -based RAG optimization model (ours) proposed in this paper performs well in all indicators, with a quality score of 0.90, knowledge consistency of 0.85, and reasoning ability of 0.91, which is significantly better than other models. This result verifies the effectiveness of our introduction of graph structure information. The graph neural network can capture the complex relationship between nodes and edges in the data, enabling the model to better handle complex knowledge reasoning tasks during the generation process and generate text with higher knowledge consistency. In addition, our model performs particularly well in reasoning ability, showing that when faced with complex problems, the retrieval-enhanced model combined with the graph structure can generate answers more accurately, indicating that the graph RAG model has significant advantages in dealing with generation tasks with structured knowledge. Overall, our model not only improves the generation quality, but also greatly improves the knowledge accuracy and reasoning depth of the generated text while maintaining a high generation speed. At the same time, we also let the model perform generation tasks under the conditions of retrieving 1, 3, 5, and 10 documents to observe the performance of the model under different document scales. Table 2  Experimental results of different document sizes Number of documents Quality KC RC 1 0.83 0.81 0.82 3 0.87 0.83 0.88 5 0.89 0.85 0.90 10 0.89 0.85 0.91  From the experimental results in Table 2, it can be seen that with the increase in the number of retrieved documents, the quality, knowledge -KC, and RC of the model have all been significantly improved, but after the number of documents increases to a certain extent, this improvement tends to be flat. When retrieving 1 document, the quality, knowledge consistency, and reasoning ability of the model are 0.83, 0.81, and 0.82, respectively. This shows that although a single document can provide some effective information, due to the limitation of the amount of information, the model is weak in complex reasoning and knowledge integration, and the generated results are limited. As the number of documents increases to 3, the model has been significantly improved in all indicators, with the quality reaching 0.87 and the reasoning ability also increased to 0.88. This shows that more documents can provide a richer source of knowledge, significantly enhancing the reasoning depth and knowledge consistency of the model. When the number of documents increases to 5, the model performs best, with quality, knowledge consistency, and reasoning ability of 0.89, 0.85, and 0.90, respectively, showing the best balance effect. However, when the number of documents further increased to 10, the model's reasoning ability slightly improved to 0.91, but the quality and knowledge consistency did not improve further, remaining at 0.89 and 0.85. This shows that too many documents will lead to information redundancy, resulting in the model being unable to effectively utilize these additional knowledge fragments, and the gain is limited. V. CONCLUSION The retrieval-augmented generation model (RAG) based on graph structure optimization proposed in this study introduces graph neural network (GNN) to process structured graph data, which significantly improves the performance of the model in complex reasoning tasks. Experimental results show that the RAG model combined with graph structure information is superior to traditional generation models in terms of generation quality, knowledge consistency and reasoning ability, especially when dealing with multi -document retrieval. When the number of document retrieval is moderate, the model can effectively utilize the external knowledge base to achieve higher quality generated text, and perform well in reasoning tasks with complex background information. Although increasing the number of retrieved documents can improve the reasoning ability of the model to a certain extent, when the number of documents is too large, information redundancy will affect the generation quality and knowledge consistency, and the gain effect is limited. This shows that there is an optimal balance point for the amount of information retrieved, and beyond this point, the performance improvement of the model tends to be flat. Overall, the graph RAG model proposed in this paper shows obvious advantages in dealing with complex knowledge reasoning and generation tasks, and this method can be further optimized and applied in more practical scenarios in the future. REFERENCES [1] Y. Zi, X. Cheng, T. Mei, Q. Wang, Z. Gao and H. Yang, \"Research on Intelligent System of Medical Image Recognition and Disease Diagnosis Based on Big Data\", Proceedings of the 2024 IEEE 2nd International Conference on Image Processing and Computer Applications (ICIPCA), pp. 825-830, 2024. [2] C. Mavromatis and G. Karypis, \"GNN -RAG: Graph Neural Retrieval for Large Language Model Reasoning,\" arXiv preprint arXiv:2405.20139, 2024. [3] G. Bénédict, R. Zhang, D. Metzler et al., \"Gen-IR@ SIGIR 2024: The Second Workshop on Generative Information Retrieval,\" Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 3029-3032, 2024. [4] G. Huang, A. Shen, Y. Hu, J. Du, J. Hu and Y. Liang, \"Optimizing YOLOv5s Object Detection through Knowledge Distillation Algorithm\", arXiv preprint arXiv:2410.12259, 2024. [5] S. Duan, R. Zhang, M. Chen, Z. Wang and S. Wang, \"Efficient and Aesthetic UI Design with a Deep Learning -Based Interface Generation Tree Algorithm\", arXiv preprint arXiv:2410.17586, 2024. [6] Y. Wu, K. Xu, H. Xia, B. Wang and N. Sang, \"Adaptive Feature Interaction Model for Credit Risk Prediction in the Digital Finance Landscape\", Journal of Computer Science and Software Applications, vol. 3, no. 1, pp. 31-38, 2023. [7] Y. Liang, X. Liu, H. Xia, Y. Cang, Z. Zheng and Y. Yang, \"Convolutional Neural Networks for Predictive Modeling of Lung Disease\", arXiv preprint arXiv:2408.12605, 2024. [8] M. Sui, J. Hu, T. Zhou, Z. Liu, L. Wen and J. Du, \"Deep Learning-Based Channel Squeeze U -Structure for Lung Nodule Detection and Segmentation\", arXiv preprint arXiv:2409.13868, 2024. [9] K. Sawarkar, A. Mangal and S. R. Solanki, \"Blended RAG: Improving RAG (Retriever -Augmented Generation) Accuracy with Semantic Search and Hybrid Query -Based Retrievers,\" 2024 IEEE 7th International Conference on Multimedia Information Processing and Retrieval (MIPR) , pp. 155-161, 2024. [10] X. Cheng, T. Mei, Y. Zi, Q. Wang, Z. Gao and H. Yang, \"Algorithm Research of ELMo Word Embedding and Deep Learning Multimodal Transformer in Image Description\", arXiv preprint arXiv:2408.06357, 2024. [11] B. Liu, I. Li, J. Yao, Y. Chen, G. Huang and J. Wang, \"Unveiling the Potential of Graph Neural Networks in SME Credit Risk Assessment\", arXiv preprint arXiv:2409.17909, 2024. [12] H. Liu, B. Zhang, Y. Xiang, Y. Hu, A. Shen and Y. Lin, \"Adversarial Neural Networks in Medical Imaging: Advancements and Challenges in Semantic Segmentation\", arXiv preprint arXiv:2410.13099, 2024. [13] W. Wang, M. Gao, M. Xiao, X. Yan, and Y. Li, \"Breast cancer image classification method based on deep transfer learning\", arXiv preprint arXiv:2404.09226, 2024. [14] J. Du, Y. Jiang, S. Lyu and Y. Liang, \"Transformers in Opinion Mining: Addressing Semantic Complexity and Model Challenges in NLP\", Transactions on Computational and Scientific Methods, vol. 4, no. 10, 2024. [15] J. Wei, Y. Liu, X. Huang, X. Zhang, W. Liu and X. Yan, \"Self -Supervised Graph Neural Networks for Enhanced Feature Extraction in Heterogeneous Information Networks\", arXiv preprint arXiv:2410.17617, 2024. [16] W. Yang, Z. Wu, Z. Zheng, B. Zhang, S. Bo and Y. Yang, \"Dynamic Hypergraph -Enhanced Prediction of Sequential Medical Visits\", arXiv preprint arXiv:2408.07084, 2024. [17] W. Liu, R. Wang, Y. Luo, J. Wei, Z. Zhao and J. Huang, \"A Recommendation Model Utilizing Separation Embedding and Self-Attention for Feature Mining\", arXiv preprint arXiv:2410.15026, 2024. [18] Y. Cang, W. Yang, D. Sun, Z. Ye and Z. Zheng, \"ALBERT -Driven Ensemble Learning for Medical Text Classification\", Journal of Computer Technology and Software, vol. 3, no. 6, 2024. [19] M. Jiang, J. Lin, H. Ouyang, J. Pan, S. Han and B. Liu, \"Wasserstein Distance -Weighted Adversarial Network for Cross-Domain Credit Risk Assessment\", arXiv preprint arXiv:2409.18544, 2024. [20] Z. Xu, J. Pan, S. Han, H. Ouyang, Y. Chen and M. Jiang, \"Predicting Liquidity Coverage Ratio with Gated Recurrent Units: A Deep Learning Model for Risk Management\", arXiv preprint arXiv:2410.19211, 2024. [21] X. Yan, Y. Jiang, W. Liu, D. Yi and J. Wei, \"Transforming Multidimensional Time Series into Interpretable Event Sequences for Advanced Data Mining\", arXiv preprint arXiv:2409.14327, 2024. [22] K. S. Kaswan, J. S. Dhatterwal, R. Batra and D. K. Yadav, \"ChatGPT: A Comprehensive Review of a Large Language Model,\" 2023 International Conference on Communication, Security and Artificial Intelligence (ICCSAI), pp. 738-743, 2023\n"
          ]
        }
      ],
      "source": [
        "print(finaltext)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R8jKubs69_k",
        "outputId": "7457faae-b280-444d-8692-1877c20b4eed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27263\n"
          ]
        }
      ],
      "source": [
        "print(len(finaltext))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5VynHVZ7BgM",
        "outputId": "d83d295a-34cd-4ab2-f2c5-0125d24db817"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "68.1575"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "27263/400"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rUyIxAe824jf"
      },
      "outputs": [],
      "source": [
        "with open(\"ragg_clean.txt\",'w',encoding=\"utf-8\") as f:\n",
        "  f.write(finaltext)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cnatc2k55gH3",
        "outputId": "1af8fdc0-6862-4d84-bb63-6fc2b783e6e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "69\n"
          ]
        }
      ],
      "source": [
        "def chunk_text(text,chunk_size=500,overlap=100):\n",
        "  chunks =[]\n",
        "  start=0\n",
        "\n",
        "  while start<len(finaltext):\n",
        "    end = start + chunk_size\n",
        "    chunk = text[start:end].strip()\n",
        "    chunks.append(chunk)\n",
        "    start=end-overlap\n",
        "\n",
        "  return chunks\n",
        "\n",
        "chunks=chunk_text(finaltext)\n",
        "print(len(chunks))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "apf2nWtg64uI"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473,
          "referenced_widgets": [
            "b1a0c8f082984e699d7a12a098e47e1e",
            "2842f004c43e4774b7eeecde72d7415c",
            "de1b720eb942409c9ae737717088d56f",
            "43316b7fc30d4e40ae82ec91d3c1db4d",
            "0d21cccbfe974688ae11514a21b29bcd",
            "fe7a3018794d4d518183900a4301ccce",
            "f0e1706a028144328f56abce17a2747b",
            "216d9971921f49b98008e6a7aafe1966",
            "1df93ff1db8748af907fe6097721012d",
            "8258baaa17a8480aaf11256d8e022c85",
            "2e71a2e5751b485eb67e9fd04ce587c3",
            "03cf903e049047dcb3badbb61e7a7ad4",
            "a17fad2cde744e72b84ba06b6af411c4",
            "bbfd9b9b04b84da2ba11036864b576f5",
            "72038476950b40da802f9e9b8c723713",
            "c672c2d6a0d04723bef05a71d40e9c91",
            "65e59ffc9abf487d8c434d756decdb7a",
            "487f86bc002445608d3a46025a3e9564",
            "83b4e63f842b483bb68158711d11048f",
            "a80ea76c8f844890a955340941a6ef95",
            "e1aea4bd9623499786e76bae61b82d80",
            "462fad073975448f9f73c3340d9aab0b",
            "65ce99cd4d5e4e72b6e7a27e1e1b6640",
            "cf39c6f45cd34b1c8c3e841b5dc62fa4",
            "8c53454fb6684252b504ae89a685b5a0",
            "dffef5e54c69462eb8db2e40c0d70b83",
            "43f4cc7e18c545f0b947c5b76be07687",
            "cdfc61d1eded4a02abf71044dc56f599",
            "8bfe0694d4fc428a83712efbd23c48f4",
            "9730640a83284f0585f079536c3110b5",
            "42d1823ca3234323ad1f65285a88f18e",
            "4257aff687d44bc1a588ff91a9f2b493",
            "7d652c64424948228b4b61b497e7da7c",
            "1eeded2b8e1e4ff48129e724ae5f0626",
            "f705da58469a44c0aa258912d58e3385",
            "d5d2fc08f93d4ebbafda3c009c776781",
            "a30ac377bc7a47a1b875b9438c14491d",
            "907e5c87e4c343cfa529e3efe176b110",
            "829770d42adc4af7aa4e67faec1c70a8",
            "b0ab72881bf84d49865c638b9606a7a4",
            "62dcdb5d477c4ab2990a9011314f74b6",
            "0bd21d635184451d8f0bb531ec9f7894",
            "7464be3fe3f947788ea78a4cb26bab98",
            "d5b6a550aa224738af2690362a3f5ade",
            "250e8ebdc67a4a2d989fede0fb08e801",
            "6e1637472f3f4a369a1a53ba70b9bb9c",
            "76286194cfba49079df394ec2338b8a9",
            "b732640d9f5447fe8b8f31690e50e917",
            "1f0f771a316148b69d88cd1f0eecc8c3",
            "6768a942489548a0b7b727e0b83bcc06",
            "88a1d0c390a14de690780a4d87bdb5c9",
            "79326dc02cf7445aa915728a0bb37e0b",
            "bfac967f13d448f8941da1d86c55d1d2",
            "684341db20b94da99be2e7ee097acc8d",
            "e3955f01e6224766899a8a887aff9f52",
            "39df7a02f7e1457c990f6141043f8c2b",
            "342ab13280204eedb0f3d4cdabcb51f8",
            "e8ea08bc445e46e2b624adab73750d69",
            "c412bf27087d466792b8b32177cafc78",
            "924e89efab5841d09c684dc9a8f4c0d0",
            "cf5de4803575450da6ad977cef141cb3",
            "bed6e952dc114706abffb01697c31036",
            "7432c069545c40c0b88730f35de6b5c4",
            "7cc6c5dd67f145d5a014514462e5da74",
            "1de3d3064e4b41b19bf8791bc5b7eb94",
            "ec6e9d48d389419cb29c5184282b9dd3",
            "1185924a3a594d0295172db9cbfbe8c0",
            "b7069c20acb24557807b11d3b9944b3b",
            "2a30f4c396e1410fa919dde3ffdbd778",
            "940c5dded1cb40e0acd086bfd5b355d6",
            "41024ff960314c9c9da9adb080866652",
            "772f89fa73354a58b87c6def25ef5c5b",
            "479239f6fb6f46759f5ff0d95a98faa4",
            "9541da96265a447ab6974c0f71c90ed0",
            "546dcfd407274cea97d2c2a10780dece",
            "59e64343568248119680d6c33bf80c69",
            "e351743764c44fa78866fb5d33958bd4",
            "4c3c2d2941b246fc963e68583411ba0b",
            "db60a438f6d543c19436fad2f2c1e714",
            "c2847e8045c24c1cbbce9805f0674f4a",
            "07ab6f75fef441d7a613ced4ca1acbfe",
            "590812cd3bc34d819cccb7034631c60a",
            "cc1ce13b16b3428bb25e47f1408a70bf",
            "573da17841d44f2aa69f0086e26f8d1d",
            "09300309382f4392b233e2170092fc83",
            "79a5bb8b30b047c49f0c73e059651fa7",
            "e9994108c74b4017869130ead45c40ba",
            "12841c9f4a2b433e8b8b0cf351e30d7a",
            "5c7ca1dbf71942b3ac883c01ab7b636f",
            "8c3ed9f55dfe4ee49374eca6569f8bee",
            "0dcdd7796d3145abb954adebdc9c049c",
            "49fbfa8796764d989101628edecef49e",
            "0f6b1b7573f14ecdbcb27b5c34ddbb71",
            "6a9b87ec100744b5b3bb13a6cc8abc88",
            "df818efe5a4c41e8acef89721dc48abf",
            "5d397a2a70214651aa5fa1d7f6cda890",
            "d7eee8e490fd4d268fc66ef061aaa76e",
            "c3e1dadfe3cd4202b8763dbc74d6a22f",
            "e7fd3cab63364c2ca45d1763e63918a6",
            "631d1d3c03ba4898a58a57131d1cf31d",
            "e8648a2f548e45e7b9b662a46b37fbd1",
            "703817dc71394878959059d0a536778e",
            "1aee9de682e748d184365ae528964778",
            "66a1f5bf8f2a4d3f9be70487a31c7be4",
            "6d5fdaf186b54784b18213a89c140581",
            "bc11987cf25443058c6527138ac302ea",
            "4070b04f0b38491cb597c1a1dde236e0",
            "e5b1d12c14bb4ba2b9231d0d25eb3a79",
            "6e528f953ece471aa7aedf887bf5fd3c",
            "d9f61a8250884e3b92b069a9b1cd7688",
            "0bcac1d080134a739c47283461475f3d",
            "00e3a535863144ef81fd0b1e177a416c",
            "ecdfd8ab90584501ac5386f19867d290",
            "9c691ec17c144eb2ae7ec302d31087af",
            "8550bed902f5461baedff604132d80f4",
            "42d19deae0664248b005d0b019ecaf45",
            "72705fcff806457baae9f9a8fe975cd4",
            "f199bedd7c754bfe823c830111a0736d",
            "56a332c9f0d541fb8796d5bfc0cc20cb",
            "38acd6f0fa16465ea6669a66fb6d6009",
            "44bf0c48a22243dd8ed872956722793e"
          ]
        },
        "id": "Rk_m1jwA7QqP",
        "outputId": "1ba15b1c-09c4-4f14-9300-4f3032561a34"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1a0c8f082984e699d7a12a098e47e1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03cf903e049047dcb3badbb61e7a7ad4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65ce99cd4d5e4e72b6e7a27e1e1b6640",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1eeded2b8e1e4ff48129e724ae5f0626",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "250e8ebdc67a4a2d989fede0fb08e801",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39df7a02f7e1457c990f6141043f8c2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1185924a3a594d0295172db9cbfbe8c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c3c2d2941b246fc963e68583411ba0b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c7ca1dbf71942b3ac883c01ab7b636f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "631d1d3c03ba4898a58a57131d1cf31d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bcac1d080134a739c47283461475f3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "724885f186c6449f9ef3eb84e66522cb",
            "8290e29d24234d37885a26714d324a37",
            "6cb0daa9a5784df6b624ace414307b54",
            "fb9e424c22994338b9eb50e54f38eac3",
            "5773ea3527df42c2be18bfbc5df3d356",
            "0b9d2212ccfb47dfb67d6887e44a4769",
            "363d56a91607423a90dda98b493d1a47",
            "8aa6802e934c4b278c64cc9fe1dfbfea",
            "1eedf9f279d74ec3a0862791aa9fbe6f",
            "b213337c29864aa6a72c8c0b29362a00",
            "85f0199864f045cf91331f331a4a4615"
          ]
        },
        "id": "ELmB-B5b7cXP",
        "outputId": "6bd9fa3d-5b2c-494d-90d1-214513dec8a0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "724885f186c6449f9ef3eb84e66522cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "embeddings=embedder.encode(\n",
        "    chunks,\n",
        "    convert_to_numpy=True,\n",
        "    show_progress_bar=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "LzxByq3p7ZGh"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "\n",
        "faiss.normalize_L2(embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "RsISd393AwYN"
      },
      "outputs": [],
      "source": [
        "dim=embeddings.shape[1]\n",
        "index = faiss.IndexFlatIP(dim)\n",
        "index.add(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "mWZ9NjKPA4dI"
      },
      "outputs": [],
      "source": [
        "def retrieve(query, k=3):\n",
        "    # Encode query\n",
        "    query_vec = embedder.encode([query], convert_to_numpy=True)\n",
        "\n",
        "    # Normalize query (NON-OPTIONAL)\n",
        "    faiss.normalize_L2(query_vec)\n",
        "\n",
        "    # Search\n",
        "    scores, indices = index.search(query_vec, k)\n",
        "\n",
        "    return scores[0], [chunks[i] for i in indices[0]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtwUCYFfCxbC",
        "outputId": "67aebf8f-6c77-4656-9a13-af328e88b3fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Result 1 | Score: 0.7137 ---\n",
            "round information. To this end, the retrieval -augmented generation model (RAG) came into being. By combining the retrieval system with the generation model, it can dynamically access external knowledge during the generation process, thereby greatly improving the quality and accuracy of generation. \n",
            "\n",
            "--- Result 2 | Score: 0.5787 ---\n",
            "eneration effect. Secondly, the synergy between the retrieval module and the generation module still needs to be further optimized. Although the current RAG model can use external information to enhance the generation effect, it still has inaccurate or incoherent generation results when dealing with\n",
            "\n",
            "--- Result 3 | Score: 0.5269 ---\n",
            "range of text -generation tasks. However, in order to further improve the performance in knowledge -intensive and reasoning tasks, we combined the design of the RAG (Retrieval Augmented Generation) model to dynamically obtain relevant information from external knowledge bases through the retrieval m\n"
          ]
        }
      ],
      "source": [
        "scores, results = retrieve(\"What is Retrieval Augmented Generation?\", k=3)\n",
        "\n",
        "for i, (score, text) in enumerate(zip(scores, results)):\n",
        "    print(f\"\\n--- Result {i+1} | Score: {score:.4f} ---\")\n",
        "    print(text[:300])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBfX-_qWC1i3",
        "outputId": "0dcf6f7a-2acb-4324-bfd6-5af3223f43a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.99999994 1.0000001\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "print(np.linalg.norm(embeddings, axis=1).min(),\n",
        "      np.linalg.norm(embeddings, axis=1).max())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwE6JYrYDM1n",
        "outputId": "b8650fea-f061-423d-c217-6009a0fbcce8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.77.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.2)\n",
            "Downloading anthropic-0.77.0-py3-none-any.whl (397 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.9/397.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.77.0\n"
          ]
        }
      ],
      "source": [
        "pip install anthropic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "6eYB9UtyF6kg"
      },
      "outputs": [],
      "source": [
        "def build_rag_prompt(context_chunks, question):\n",
        "    context = \"\\n\\n\".join(context_chunks)\n",
        "\n",
        "    return f\"\"\"\n",
        "You are a factual assistant.\n",
        "Answer the question using ONLY the context below.\n",
        "If the answer is not present, say \"I don't know\".\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "_vtgPxzSIu2Y",
        "outputId": "71acdb4b-2a73-4833-99fd-846461a1570d"
      },
      "outputs": [
        {
          "ename": "AuthenticationError",
          "evalue": "Error code: 401 - {'type': 'error', 'error': {'type': 'authentication_error', 'message': 'invalid x-api-key'}, 'request_id': 'req_011CXdHpKFn1zSqq94GG8EbN'}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4047110731.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_rag_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieved_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mask_claude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2796972583.py\u001b[0m in \u001b[0;36mask_claude\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mask_claude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     response = client.messages.create(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"claude-opus-4-5-20251101\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/anthropic/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/anthropic/resources/messages/messages.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, max_tokens, messages, model, metadata, output_config, service_tier, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    948\u001b[0m             )\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    951\u001b[0m             \u001b[0;34m\"/v1/messages\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, content, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         )\n\u001b[0;32m-> 1364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'type': 'error', 'error': {'type': 'authentication_error', 'message': 'invalid x-api-key'}, 'request_id': 'req_011CXdHpKFn1zSqq94GG8EbN'}"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7Ho656tIk3U",
        "outputId": "afe3b8ad-75a0-45b1-c8b8-0f34881498bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer:\n",
            " Based on the context provided, **Graph RAG** is a model that combines the Retrieval-Augmented Generation (RAG) model with graph structure. It uses graph structure data (which expresses complex relationships between different objects in the form of nodes and edges) and incorporates technologies such as graph neural networks (GNNs) to better process structured knowledge and extract valuable information.\n",
            "\n",
            "The Graph RAG model can:\n",
            "- Better handle complex knowledge reasoning and generation tasks\n",
            "- Process associations between structured information\n",
            "- Improve the generation quality and rationality of the model\n",
            "\n",
            "In practical applications, such as the medical field, the Graph RAG model can be used for tasks like medical record generation and diagnosis assistance, where it can better handle associations between structured information like patient history, diagnoses, and treatment plans.\n"
          ]
        }
      ],
      "source": [
        "from anthropic import Anthropic\n",
        "\n",
        "# Initialize the client with your API key\n",
        "client = Anthropic(api_key=\"\")\n",
        "\n",
        "def ask_claude(prompt):\n",
        "    # Send the prompt to Claude via the Messages API\n",
        "    response = client.messages.create(\n",
        "        model=\"claude-opus-4-5-20251101\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=600,\n",
        "        temperature=0.0\n",
        "    )\n",
        "    # Extract the text response\n",
        "    # Depending on the SDK version, you can access the text like this:\n",
        "    return response.content[0].text\n",
        "\n",
        "\n",
        "# Example usage (RAG context)\n",
        "\n",
        "question = \"What is graph rag\"\n",
        "\n",
        "# Perform retrieval using your FAISS retrieval function\n",
        "scores, retrieved_chunks = retrieve(question, k=3)\n",
        "\n",
        "# Build the RAG prompt with your function\n",
        "prompt = build_rag_prompt(retrieved_chunks, question)\n",
        "\n",
        "# Make the Claude call\n",
        "answer = ask_claude(prompt)\n",
        "\n",
        "print(\"Answer:\\n\", answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "pOFdjYw3Ilc4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0VjaLoLKhoe"
      },
      "source": [
        "# **imporved rag with metada chnaging or adding how we store stuff**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "FVydDP8CKqNw"
      },
      "outputs": [],
      "source": [
        "from pypdf import PdfReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KNF-XAcK2JG",
        "outputId": "6cbe9c63-a4a0-461c-b026-688806fa24fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pages loaded: 1\n"
          ]
        }
      ],
      "source": [
        "def load_pdf_with_pages(path):\n",
        "  text_with_page = []\n",
        "  reader = PdfReader(path)\n",
        "  for i, page in enumerate(reader.pages):\n",
        "    page_text = page.extract_text() or \"\"\n",
        "    page_text = page_text.strip()\n",
        "    text_with_page.append((i + 1, page_text))\n",
        "    return text_with_page\n",
        "pdf_pages = load_pdf_with_pages(\"/content/RAGG.pdf\")\n",
        "print(\"Pages loaded:\", len(pdf_pages))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T07AuVBVMInj",
        "outputId": "0151d4bc-871f-409f-bb8b-8fa12c74bf7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total pages in PDF: 5\n",
            "Page 1: extracted text length = 4809\n",
            "Page 2: extracted text length = 5640\n",
            "Page 3: extracted text length = 5629\n",
            "Page 4: extracted text length = 5855\n",
            "Page 5: extracted text length = 5982\n"
          ]
        }
      ],
      "source": [
        "from pypdf import PdfReader\n",
        "\n",
        "reader = PdfReader(\"/content/RAGG.pdf\")\n",
        "print(\"Total pages in PDF:\", len(reader.pages))\n",
        "\n",
        "for i, page in enumerate(reader.pages):\n",
        "    txt = page.extract_text()\n",
        "    print(f\"Page {i+1}: extracted text length = {len(txt) if txt else 0}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAEx9tniM0gS",
        "outputId": "77592515-e3cd-4d9e-ee2a-c5862a144c03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total pages in loader: 5\n",
            "Page 1 length: 4809\n",
            "Page 2 length: 5639\n",
            "Page 3 length: 5628\n",
            "Page 4 length: 5854\n",
            "Page 5 length: 5967\n"
          ]
        }
      ],
      "source": [
        "from pypdf import PdfReader\n",
        "\n",
        "def load_pdf_with_pages(path):\n",
        "    reader = PdfReader(path)\n",
        "    pages = []\n",
        "\n",
        "    for i, page in enumerate(reader.pages):\n",
        "        # extract text; fallback to empty string\n",
        "        page_text = page.extract_text() or \"\"\n",
        "        # strip leading/trailing whitespace\n",
        "        cleaned = page_text.strip()\n",
        "\n",
        "        # Always append with page number (even if empty)\n",
        "        pages.append((i + 1, cleaned))\n",
        "\n",
        "    return pages\n",
        "\n",
        "# load the PDF\n",
        "pdf_pages = load_pdf_with_pages(\"/content/RAGG.pdf\")\n",
        "\n",
        "print(\"Total pages in loader:\", len(pdf_pages))\n",
        "for p, txt in pdf_pages:\n",
        "    print(f\"Page {p} length:\", len(txt))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "fj2iEQI2NADo"
      },
      "outputs": [],
      "source": [
        "def chunk_with_metadata(pages, chunk_size=500, overlap=100):\n",
        "    \"\"\"\n",
        "    pages: list of (page_number, page_text)\n",
        "    returns:\n",
        "      list of {\"text\": ..., \"pages\": [...]} dictionaries\n",
        "    \"\"\"\n",
        "\n",
        "    chunks = []\n",
        "    buffer_text = \"\"\n",
        "    buffer_pages = set()\n",
        "\n",
        "    for page_num, page_txt in pages:\n",
        "        pos = 0\n",
        "\n",
        "        # Slide across this page text\n",
        "        while pos < len(page_txt):\n",
        "            piece = page_txt[pos:pos + chunk_size]\n",
        "\n",
        "            if piece.strip():\n",
        "                buffer_text += piece\n",
        "                buffer_pages.add(page_num)\n",
        "\n",
        "            # When buffer_text is large enough, emit a chunk\n",
        "            if len(buffer_text) >= chunk_size:\n",
        "                chunks.append({\n",
        "                    \"text\": buffer_text.strip(),\n",
        "                    \"pages\": sorted(buffer_pages)\n",
        "                })\n",
        "                # Create overlap\n",
        "                buffer_text = buffer_text[-overlap:]\n",
        "                buffer_pages = {page_num}\n",
        "\n",
        "            pos += chunk_size\n",
        "\n",
        "    # Add any leftover text as a final chunk\n",
        "    if buffer_text.strip():\n",
        "        chunks.append({\n",
        "            \"text\": buffer_text.strip(),\n",
        "            \"pages\": sorted(buffer_pages)\n",
        "        })\n",
        "\n",
        "    return chunks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShLemGV_N8_H",
        "outputId": "c8db8f14-f31d-4988-a497-73daace2f184"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total chunks: 55\n",
            "{'text': 'Advanced RAG Models with Graph Structures: \\nOptimizing Complex Knowledge Reasoning and Text \\nGeneration \\n  \\n  \\n  \\n  \\n \\n  \\n  \\n  \\n  \\n \\n  \\n  \\n  \\n  \\n \\n  \\n  \\n  \\n \\n  \\n  \\n  \\n \\n  \\n  \\n  \\n  \\n \\n \\nAbstract—This study aims to optimize the existing \\nretrieval-augmented generation model (RAG) by \\nintroducing a graph structure to improve the performance \\nof the model in dealing with complex knowledge reasoning \\ntasks. The traditional RAG model has the problem of \\ninsufficient processing efficiency when facing c', 'pages': [1]}\n"
          ]
        }
      ],
      "source": [
        "pdf_pages = load_pdf_with_pages(\"/content/RAGG.pdf\")\n",
        "chunks_with_meta = chunk_with_metadata(pdf_pages)\n",
        "\n",
        "print(\"Total chunks:\", len(chunks_with_meta))\n",
        "print(chunks_with_meta[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "ymtQ2pS-OF7p"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def clean_text(text):\n",
        "    # Normalize unicode (remove ligatures, smart quotes)\n",
        "    text = unicodedata.normalize(\"NFKD\", text)\n",
        "\n",
        "    # Replace newlines with spaces\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "\n",
        "    # Collapse multiple spaces into one\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "j7ke0CGvOZzI"
      },
      "outputs": [],
      "source": [
        "def chunk_with_clean_metadata(pages, chunk_size=500, overlap=100):\n",
        "    chunks = []\n",
        "    buffer_text = \"\"\n",
        "    buffer_pages = set()\n",
        "\n",
        "    for page_num, page_txt in pages:\n",
        "        # Clean the page text first\n",
        "        page = clean_text(page_txt)\n",
        "\n",
        "        pos = 0\n",
        "        while pos < len(page):\n",
        "            piece = page[pos:pos + chunk_size]\n",
        "\n",
        "            if piece.strip():\n",
        "                buffer_text += piece + \" \"\n",
        "                buffer_pages.add(page_num)\n",
        "\n",
        "            # When enough text for a chunk\n",
        "            if len(buffer_text) >= chunk_size:\n",
        "                chunks.append({\n",
        "                    \"text\": buffer_text.strip(),\n",
        "                    \"pages\": sorted(buffer_pages)\n",
        "                })\n",
        "                buffer_text = buffer_text[-overlap:]\n",
        "                buffer_pages = {page_num}\n",
        "\n",
        "            pos += chunk_size\n",
        "\n",
        "    # leftover\n",
        "    if buffer_text.strip():\n",
        "        chunks.append({\n",
        "            \"text\": buffer_text.strip(),\n",
        "            \"pages\": sorted(buffer_pages)\n",
        "        })\n",
        "\n",
        "    return chunks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1T_hYL1OdIv",
        "outputId": "f4833524-e08c-45b4-dc63-566271b82fa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total clean chunks: 54\n"
          ]
        }
      ],
      "source": [
        "pdf_pages = load_pdf_with_pages(\"/content/RAGG.pdf\")\n",
        "clean_chunks = chunk_with_clean_metadata(pdf_pages)\n",
        "\n",
        "print(\"Total clean chunks:\", len(clean_chunks))\n",
        "# print(clean_chunks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "59912ac043b94842b41854f6b163cfb5",
            "52d860d105e541cd9d3db379134d72a6",
            "2f6d9c3ac6b147a7bf23e974a8544ded",
            "f1e2f6d7dbe24487aa980ac7be210809",
            "c21a6907535d4befb81e126bee1aa724",
            "1e2d436a95114b27ac42b3ade798ac6b",
            "193f4c10c0dd43639e4334eb620491b4",
            "3b9bbc721427400eb2cceea0e0e86fd8",
            "84431cd71def4b64ad832d59c9075a70",
            "91271be843084fa183e5160c2713f6c7",
            "178573b245114eea9f82b828e8052bad"
          ]
        },
        "id": "uMIG914VOfmt",
        "outputId": "e7a49f37-afdc-459b-f1c6-e4c0860c7f95"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59912ac043b94842b41854f6b163cfb5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index built. Total vectors: 55\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "\n",
        "# 1) Initialize the embedder\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# 2) Prepare list of chunk texts\n",
        "texts = [chunk[\"text\"] for chunk in chunks_with_meta]\n",
        "\n",
        "# 3) Generate embeddings\n",
        "embeddings = embedder.encode(\n",
        "    texts,\n",
        "    convert_to_numpy=True,\n",
        "    show_progress_bar=True\n",
        ")\n",
        "\n",
        "# 4) Normalize embeddings so dot product = cosine similarity\n",
        "faiss.normalize_L2(embeddings)\n",
        "\n",
        "# 5) Create a FAISS index for Inner Product\n",
        "dim = embeddings.shape[1]\n",
        "index = faiss.IndexFlatIP(dim)\n",
        "index.add(embeddings)\n",
        "\n",
        "print(\"FAISS index built. Total vectors:\", index.ntotal)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "leE9bdWoQJ5K"
      },
      "outputs": [],
      "source": [
        "def retrieve_with_meta(query, k=3):\n",
        "    # Embed the query\n",
        "    q_emb = embedder.encode([query], convert_to_numpy=True)\n",
        "\n",
        "    # Normalize the query (MANDATORY for cosine)\n",
        "    faiss.normalize_L2(q_emb)\n",
        "\n",
        "    # Search FAISS\n",
        "    scores, indices = index.search(q_emb, k)\n",
        "\n",
        "    results = []\n",
        "    for score, idx in zip(scores[0], indices[0]):\n",
        "        chunk = chunks_with_meta[idx]\n",
        "        results.append({\n",
        "            \"score\": float(score),\n",
        "            \"text\": chunk[\"text\"],\n",
        "            \"pages\": chunk[\"pages\"]\n",
        "        })\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "fQZ_DLYRRXLM"
      },
      "outputs": [],
      "source": [
        "def build_rag_prompt_with_meta(retrieved, question):\n",
        "    context_str = \"\"\n",
        "    for i, item in enumerate(retrieved):\n",
        "        pages = \", \".join(map(str, item[\"pages\"]))\n",
        "        context_str += f\"[Chunk {i+1} | Pages {pages}]\\n{item['text']}\\n\\n\"\n",
        "\n",
        "    return f\"\"\"\n",
        "You are a factual assistant. Answer using ONLY the context below.\n",
        "If the answer isn’t in the context, say \"I don't know\".\n",
        "\n",
        "Context:\n",
        "{context_str}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWDNObMSRZEX"
      },
      "outputs": [],
      "source": [
        "from anthropic import Anthropic\n",
        "\n",
        "client = Anthropic(api_key=\"\")\n",
        "\n",
        "def ask_claude(prompt):\n",
        "    response = client.messages.create(\n",
        "        model=\"claude-opus-4-5-20251101\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=600,\n",
        "        temperature=0.0,\n",
        "    )\n",
        "    return response.content[0].text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUJ5YXiVRiZa",
        "outputId": "7b1cee61-7886-451b-ea61-35daecd01fb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved chunks: 3 [{'score': 0.7139130234718323, 'text': 'or learning. Although these models can generate \\nrelatively coherent text, their generation ability is still limited \\nwhen facing external knowledge or complex background \\ninformation. To this end, the retrieval -augmented generation \\nmodel (RAG) came into being. By combining the retrieval \\nsystem with the generation model, it can dynamically access \\nexternal knowledge during the generation process, thereby \\ngreatly improving the quality and accuracy of generation. \\nEspecially in tasks that require a rich knowledge background or \\ncomplex reasoning, the RAG model shows stronger advantages \\nthan', 'pages': [1]}, {'score': 0.5119883418083191, 'text': 'on capabilities and can handle a \\nwide range of text -generation tasks. However, in order to \\nfurther improve the performance in knowledge -intensive and \\nreasoning tasks, we combined the design of the RAG (Retrieval \\nAugmented Generation) model to dynamically obtain relevant \\ninformation from external knowledge bases through the \\nretrieval module to generate more knowledge -accurate and \\nrelevant answers. This architecture can effectively make up for \\nthe problem that the generative model relies solely on training \\ndata, enabling it to handle knowledge reasoning and complex \\ntasks in more fie', 'pages': [3]}, {'score': 0.5027644634246826, 'text': \"hances the Retrieval -Augmented Generation \\n(RAG) model by incorporating graph structures through Graph \\nNeural Networks (GNNs) to support complex reasoning and \\nimprove generation quality. Prior research has informed \\nvarious aspects of this work, from foundational NLP \\nimprovements to methodologies for structuring and processing \\ncomplex, interconnected data. \\nA central component of the RAG model is the transformer \\narchitecture, which has been instrumental in handling semantic \\ncomplexity. Du et al. [14] discuss transformers' applications in \\nmanaging intricate semantic information in natur\", 'pages': [2]}]\n",
            "Answer:\n",
            " Based on the context provided, Retrieval Augmented Generation (RAG) is a model that combines a retrieval system with a generation model. It can dynamically access external knowledge during the generation process, thereby greatly improving the quality and accuracy of generation. The RAG model dynamically obtains relevant information from external knowledge bases through a retrieval module to generate more knowledge-accurate and relevant answers. This architecture effectively addresses the problem of generative models relying solely on training data, enabling them to handle knowledge reasoning and complex tasks. RAG shows stronger advantages in tasks that require a rich knowledge background or complex reasoning.\n"
          ]
        }
      ],
      "source": [
        "question = \"What is Retrieval Augmented Generation?\"\n",
        "\n",
        "# 1) Retrieve\n",
        "retrieved = retrieve_with_meta(question, k=3)\n",
        "print(\"Retrieved chunks:\", len(retrieved),retrieved)\n",
        "# 2) Build prompt\n",
        "prompt = build_rag_prompt_with_meta(retrieved, question)\n",
        "\n",
        "# 3) Ask Claude\n",
        "answer = ask_claude(prompt)\n",
        "\n",
        "print(\"Answer:\\n\", answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvRhuQXCRk7V"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00e3a535863144ef81fd0b1e177a416c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42d19deae0664248b005d0b019ecaf45",
            "placeholder": "​",
            "style": "IPY_MODEL_72705fcff806457baae9f9a8fe975cd4",
            "value": "config.json: 100%"
          }
        },
        "03cf903e049047dcb3badbb61e7a7ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a17fad2cde744e72b84ba06b6af411c4",
              "IPY_MODEL_bbfd9b9b04b84da2ba11036864b576f5",
              "IPY_MODEL_72038476950b40da802f9e9b8c723713"
            ],
            "layout": "IPY_MODEL_c672c2d6a0d04723bef05a71d40e9c91"
          }
        },
        "07ab6f75fef441d7a613ced4ca1acbfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9994108c74b4017869130ead45c40ba",
            "placeholder": "​",
            "style": "IPY_MODEL_12841c9f4a2b433e8b8b0cf351e30d7a",
            "value": " 232k/? [00:00&lt;00:00, 7.24MB/s]"
          }
        },
        "09300309382f4392b233e2170092fc83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0b9d2212ccfb47dfb67d6887e44a4769": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bcac1d080134a739c47283461475f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00e3a535863144ef81fd0b1e177a416c",
              "IPY_MODEL_ecdfd8ab90584501ac5386f19867d290",
              "IPY_MODEL_9c691ec17c144eb2ae7ec302d31087af"
            ],
            "layout": "IPY_MODEL_8550bed902f5461baedff604132d80f4"
          }
        },
        "0bd21d635184451d8f0bb531ec9f7894": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d21cccbfe974688ae11514a21b29bcd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dcdd7796d3145abb954adebdc9c049c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d397a2a70214651aa5fa1d7f6cda890",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7eee8e490fd4d268fc66ef061aaa76e",
            "value": 1
          }
        },
        "0f6b1b7573f14ecdbcb27b5c34ddbb71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1185924a3a594d0295172db9cbfbe8c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7069c20acb24557807b11d3b9944b3b",
              "IPY_MODEL_2a30f4c396e1410fa919dde3ffdbd778",
              "IPY_MODEL_940c5dded1cb40e0acd086bfd5b355d6"
            ],
            "layout": "IPY_MODEL_41024ff960314c9c9da9adb080866652"
          }
        },
        "12841c9f4a2b433e8b8b0cf351e30d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "178573b245114eea9f82b828e8052bad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "193f4c10c0dd43639e4334eb620491b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1aee9de682e748d184365ae528964778": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e528f953ece471aa7aedf887bf5fd3c",
            "placeholder": "​",
            "style": "IPY_MODEL_d9f61a8250884e3b92b069a9b1cd7688",
            "value": " 112/112 [00:00&lt;00:00, 9.73kB/s]"
          }
        },
        "1de3d3064e4b41b19bf8791bc5b7eb94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1df93ff1db8748af907fe6097721012d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e2d436a95114b27ac42b3ade798ac6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1eeded2b8e1e4ff48129e724ae5f0626": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f705da58469a44c0aa258912d58e3385",
              "IPY_MODEL_d5d2fc08f93d4ebbafda3c009c776781",
              "IPY_MODEL_a30ac377bc7a47a1b875b9438c14491d"
            ],
            "layout": "IPY_MODEL_907e5c87e4c343cfa529e3efe176b110"
          }
        },
        "1eedf9f279d74ec3a0862791aa9fbe6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f0f771a316148b69d88cd1f0eecc8c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "216d9971921f49b98008e6a7aafe1966": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "250e8ebdc67a4a2d989fede0fb08e801": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e1637472f3f4a369a1a53ba70b9bb9c",
              "IPY_MODEL_76286194cfba49079df394ec2338b8a9",
              "IPY_MODEL_b732640d9f5447fe8b8f31690e50e917"
            ],
            "layout": "IPY_MODEL_1f0f771a316148b69d88cd1f0eecc8c3"
          }
        },
        "2842f004c43e4774b7eeecde72d7415c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe7a3018794d4d518183900a4301ccce",
            "placeholder": "​",
            "style": "IPY_MODEL_f0e1706a028144328f56abce17a2747b",
            "value": "modules.json: 100%"
          }
        },
        "2a30f4c396e1410fa919dde3ffdbd778": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9541da96265a447ab6974c0f71c90ed0",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_546dcfd407274cea97d2c2a10780dece",
            "value": 350
          }
        },
        "2e71a2e5751b485eb67e9fd04ce587c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f6d9c3ac6b147a7bf23e974a8544ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b9bbc721427400eb2cceea0e0e86fd8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84431cd71def4b64ad832d59c9075a70",
            "value": 2
          }
        },
        "342ab13280204eedb0f3d4cdabcb51f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf5de4803575450da6ad977cef141cb3",
            "placeholder": "​",
            "style": "IPY_MODEL_bed6e952dc114706abffb01697c31036",
            "value": "model.safetensors: 100%"
          }
        },
        "363d56a91607423a90dda98b493d1a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38acd6f0fa16465ea6669a66fb6d6009": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39df7a02f7e1457c990f6141043f8c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_342ab13280204eedb0f3d4cdabcb51f8",
              "IPY_MODEL_e8ea08bc445e46e2b624adab73750d69",
              "IPY_MODEL_c412bf27087d466792b8b32177cafc78"
            ],
            "layout": "IPY_MODEL_924e89efab5841d09c684dc9a8f4c0d0"
          }
        },
        "3b9bbc721427400eb2cceea0e0e86fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4070b04f0b38491cb597c1a1dde236e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41024ff960314c9c9da9adb080866652": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4257aff687d44bc1a588ff91a9f2b493": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42d1823ca3234323ad1f65285a88f18e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42d19deae0664248b005d0b019ecaf45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43316b7fc30d4e40ae82ec91d3c1db4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8258baaa17a8480aaf11256d8e022c85",
            "placeholder": "​",
            "style": "IPY_MODEL_2e71a2e5751b485eb67e9fd04ce587c3",
            "value": " 349/349 [00:00&lt;00:00, 29.0kB/s]"
          }
        },
        "43f4cc7e18c545f0b947c5b76be07687": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44bf0c48a22243dd8ed872956722793e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "462fad073975448f9f73c3340d9aab0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "479239f6fb6f46759f5ff0d95a98faa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "487f86bc002445608d3a46025a3e9564": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49fbfa8796764d989101628edecef49e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3e1dadfe3cd4202b8763dbc74d6a22f",
            "placeholder": "​",
            "style": "IPY_MODEL_e7fd3cab63364c2ca45d1763e63918a6",
            "value": " 466k/? [00:00&lt;00:00, 22.4MB/s]"
          }
        },
        "4c3c2d2941b246fc963e68583411ba0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db60a438f6d543c19436fad2f2c1e714",
              "IPY_MODEL_c2847e8045c24c1cbbce9805f0674f4a",
              "IPY_MODEL_07ab6f75fef441d7a613ced4ca1acbfe"
            ],
            "layout": "IPY_MODEL_590812cd3bc34d819cccb7034631c60a"
          }
        },
        "52d860d105e541cd9d3db379134d72a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e2d436a95114b27ac42b3ade798ac6b",
            "placeholder": "​",
            "style": "IPY_MODEL_193f4c10c0dd43639e4334eb620491b4",
            "value": "Batches: 100%"
          }
        },
        "546dcfd407274cea97d2c2a10780dece": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56a332c9f0d541fb8796d5bfc0cc20cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "573da17841d44f2aa69f0086e26f8d1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5773ea3527df42c2be18bfbc5df3d356": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "590812cd3bc34d819cccb7034631c60a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59912ac043b94842b41854f6b163cfb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52d860d105e541cd9d3db379134d72a6",
              "IPY_MODEL_2f6d9c3ac6b147a7bf23e974a8544ded",
              "IPY_MODEL_f1e2f6d7dbe24487aa980ac7be210809"
            ],
            "layout": "IPY_MODEL_c21a6907535d4befb81e126bee1aa724"
          }
        },
        "59e64343568248119680d6c33bf80c69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c7ca1dbf71942b3ac883c01ab7b636f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c3ed9f55dfe4ee49374eca6569f8bee",
              "IPY_MODEL_0dcdd7796d3145abb954adebdc9c049c",
              "IPY_MODEL_49fbfa8796764d989101628edecef49e"
            ],
            "layout": "IPY_MODEL_0f6b1b7573f14ecdbcb27b5c34ddbb71"
          }
        },
        "5d397a2a70214651aa5fa1d7f6cda890": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "62dcdb5d477c4ab2990a9011314f74b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "631d1d3c03ba4898a58a57131d1cf31d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8648a2f548e45e7b9b662a46b37fbd1",
              "IPY_MODEL_703817dc71394878959059d0a536778e",
              "IPY_MODEL_1aee9de682e748d184365ae528964778"
            ],
            "layout": "IPY_MODEL_66a1f5bf8f2a4d3f9be70487a31c7be4"
          }
        },
        "65ce99cd4d5e4e72b6e7a27e1e1b6640": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf39c6f45cd34b1c8c3e841b5dc62fa4",
              "IPY_MODEL_8c53454fb6684252b504ae89a685b5a0",
              "IPY_MODEL_dffef5e54c69462eb8db2e40c0d70b83"
            ],
            "layout": "IPY_MODEL_43f4cc7e18c545f0b947c5b76be07687"
          }
        },
        "65e59ffc9abf487d8c434d756decdb7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a1f5bf8f2a4d3f9be70487a31c7be4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6768a942489548a0b7b727e0b83bcc06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "684341db20b94da99be2e7ee097acc8d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a9b87ec100744b5b3bb13a6cc8abc88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cb0daa9a5784df6b624ace414307b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aa6802e934c4b278c64cc9fe1dfbfea",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1eedf9f279d74ec3a0862791aa9fbe6f",
            "value": 3
          }
        },
        "6d5fdaf186b54784b18213a89c140581": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e1637472f3f4a369a1a53ba70b9bb9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6768a942489548a0b7b727e0b83bcc06",
            "placeholder": "​",
            "style": "IPY_MODEL_88a1d0c390a14de690780a4d87bdb5c9",
            "value": "config.json: 100%"
          }
        },
        "6e528f953ece471aa7aedf887bf5fd3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "703817dc71394878959059d0a536778e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4070b04f0b38491cb597c1a1dde236e0",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5b1d12c14bb4ba2b9231d0d25eb3a79",
            "value": 112
          }
        },
        "72038476950b40da802f9e9b8c723713": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1aea4bd9623499786e76bae61b82d80",
            "placeholder": "​",
            "style": "IPY_MODEL_462fad073975448f9f73c3340d9aab0b",
            "value": " 116/116 [00:00&lt;00:00, 10.6kB/s]"
          }
        },
        "724885f186c6449f9ef3eb84e66522cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8290e29d24234d37885a26714d324a37",
              "IPY_MODEL_6cb0daa9a5784df6b624ace414307b54",
              "IPY_MODEL_fb9e424c22994338b9eb50e54f38eac3"
            ],
            "layout": "IPY_MODEL_5773ea3527df42c2be18bfbc5df3d356"
          }
        },
        "72705fcff806457baae9f9a8fe975cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7432c069545c40c0b88730f35de6b5c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7464be3fe3f947788ea78a4cb26bab98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76286194cfba49079df394ec2338b8a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79326dc02cf7445aa915728a0bb37e0b",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfac967f13d448f8941da1d86c55d1d2",
            "value": 612
          }
        },
        "772f89fa73354a58b87c6def25ef5c5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79326dc02cf7445aa915728a0bb37e0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79a5bb8b30b047c49f0c73e059651fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7cc6c5dd67f145d5a014514462e5da74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d652c64424948228b4b61b497e7da7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8258baaa17a8480aaf11256d8e022c85": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8290e29d24234d37885a26714d324a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b9d2212ccfb47dfb67d6887e44a4769",
            "placeholder": "​",
            "style": "IPY_MODEL_363d56a91607423a90dda98b493d1a47",
            "value": "Batches: 100%"
          }
        },
        "829770d42adc4af7aa4e67faec1c70a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83b4e63f842b483bb68158711d11048f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84431cd71def4b64ad832d59c9075a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8550bed902f5461baedff604132d80f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85f0199864f045cf91331f331a4a4615": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88a1d0c390a14de690780a4d87bdb5c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8aa6802e934c4b278c64cc9fe1dfbfea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bfe0694d4fc428a83712efbd23c48f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c3ed9f55dfe4ee49374eca6569f8bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a9b87ec100744b5b3bb13a6cc8abc88",
            "placeholder": "​",
            "style": "IPY_MODEL_df818efe5a4c41e8acef89721dc48abf",
            "value": "tokenizer.json: "
          }
        },
        "8c53454fb6684252b504ae89a685b5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9730640a83284f0585f079536c3110b5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42d1823ca3234323ad1f65285a88f18e",
            "value": 1
          }
        },
        "907e5c87e4c343cfa529e3efe176b110": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91271be843084fa183e5160c2713f6c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "924e89efab5841d09c684dc9a8f4c0d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "940c5dded1cb40e0acd086bfd5b355d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59e64343568248119680d6c33bf80c69",
            "placeholder": "​",
            "style": "IPY_MODEL_e351743764c44fa78866fb5d33958bd4",
            "value": " 350/350 [00:00&lt;00:00, 31.0kB/s]"
          }
        },
        "9541da96265a447ab6974c0f71c90ed0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9730640a83284f0585f079536c3110b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9c691ec17c144eb2ae7ec302d31087af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38acd6f0fa16465ea6669a66fb6d6009",
            "placeholder": "​",
            "style": "IPY_MODEL_44bf0c48a22243dd8ed872956722793e",
            "value": " 190/190 [00:00&lt;00:00, 8.40kB/s]"
          }
        },
        "a17fad2cde744e72b84ba06b6af411c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65e59ffc9abf487d8c434d756decdb7a",
            "placeholder": "​",
            "style": "IPY_MODEL_487f86bc002445608d3a46025a3e9564",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "a30ac377bc7a47a1b875b9438c14491d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7464be3fe3f947788ea78a4cb26bab98",
            "placeholder": "​",
            "style": "IPY_MODEL_d5b6a550aa224738af2690362a3f5ade",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.77kB/s]"
          }
        },
        "a80ea76c8f844890a955340941a6ef95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0ab72881bf84d49865c638b9606a7a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1a0c8f082984e699d7a12a098e47e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2842f004c43e4774b7eeecde72d7415c",
              "IPY_MODEL_de1b720eb942409c9ae737717088d56f",
              "IPY_MODEL_43316b7fc30d4e40ae82ec91d3c1db4d"
            ],
            "layout": "IPY_MODEL_0d21cccbfe974688ae11514a21b29bcd"
          }
        },
        "b213337c29864aa6a72c8c0b29362a00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7069c20acb24557807b11d3b9944b3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_772f89fa73354a58b87c6def25ef5c5b",
            "placeholder": "​",
            "style": "IPY_MODEL_479239f6fb6f46759f5ff0d95a98faa4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b732640d9f5447fe8b8f31690e50e917": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_684341db20b94da99be2e7ee097acc8d",
            "placeholder": "​",
            "style": "IPY_MODEL_e3955f01e6224766899a8a887aff9f52",
            "value": " 612/612 [00:00&lt;00:00, 40.9kB/s]"
          }
        },
        "bbfd9b9b04b84da2ba11036864b576f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83b4e63f842b483bb68158711d11048f",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a80ea76c8f844890a955340941a6ef95",
            "value": 116
          }
        },
        "bc11987cf25443058c6527138ac302ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bed6e952dc114706abffb01697c31036": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfac967f13d448f8941da1d86c55d1d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c21a6907535d4befb81e126bee1aa724": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2847e8045c24c1cbbce9805f0674f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09300309382f4392b233e2170092fc83",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79a5bb8b30b047c49f0c73e059651fa7",
            "value": 1
          }
        },
        "c3e1dadfe3cd4202b8763dbc74d6a22f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c412bf27087d466792b8b32177cafc78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1de3d3064e4b41b19bf8791bc5b7eb94",
            "placeholder": "​",
            "style": "IPY_MODEL_ec6e9d48d389419cb29c5184282b9dd3",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 135MB/s]"
          }
        },
        "c672c2d6a0d04723bef05a71d40e9c91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc1ce13b16b3428bb25e47f1408a70bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdfc61d1eded4a02abf71044dc56f599": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf39c6f45cd34b1c8c3e841b5dc62fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdfc61d1eded4a02abf71044dc56f599",
            "placeholder": "​",
            "style": "IPY_MODEL_8bfe0694d4fc428a83712efbd23c48f4",
            "value": "README.md: "
          }
        },
        "cf5de4803575450da6ad977cef141cb3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5b6a550aa224738af2690362a3f5ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5d2fc08f93d4ebbafda3c009c776781": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62dcdb5d477c4ab2990a9011314f74b6",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0bd21d635184451d8f0bb531ec9f7894",
            "value": 53
          }
        },
        "d7eee8e490fd4d268fc66ef061aaa76e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9f61a8250884e3b92b069a9b1cd7688": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db60a438f6d543c19436fad2f2c1e714": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc1ce13b16b3428bb25e47f1408a70bf",
            "placeholder": "​",
            "style": "IPY_MODEL_573da17841d44f2aa69f0086e26f8d1d",
            "value": "vocab.txt: "
          }
        },
        "de1b720eb942409c9ae737717088d56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_216d9971921f49b98008e6a7aafe1966",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1df93ff1db8748af907fe6097721012d",
            "value": 349
          }
        },
        "df818efe5a4c41e8acef89721dc48abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dffef5e54c69462eb8db2e40c0d70b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4257aff687d44bc1a588ff91a9f2b493",
            "placeholder": "​",
            "style": "IPY_MODEL_7d652c64424948228b4b61b497e7da7c",
            "value": " 10.5k/? [00:00&lt;00:00, 462kB/s]"
          }
        },
        "e1aea4bd9623499786e76bae61b82d80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e351743764c44fa78866fb5d33958bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3955f01e6224766899a8a887aff9f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5b1d12c14bb4ba2b9231d0d25eb3a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7fd3cab63364c2ca45d1763e63918a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8648a2f548e45e7b9b662a46b37fbd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d5fdaf186b54784b18213a89c140581",
            "placeholder": "​",
            "style": "IPY_MODEL_bc11987cf25443058c6527138ac302ea",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e8ea08bc445e46e2b624adab73750d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7432c069545c40c0b88730f35de6b5c4",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7cc6c5dd67f145d5a014514462e5da74",
            "value": 90868376
          }
        },
        "e9994108c74b4017869130ead45c40ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec6e9d48d389419cb29c5184282b9dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecdfd8ab90584501ac5386f19867d290": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f199bedd7c754bfe823c830111a0736d",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56a332c9f0d541fb8796d5bfc0cc20cb",
            "value": 190
          }
        },
        "f0e1706a028144328f56abce17a2747b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f199bedd7c754bfe823c830111a0736d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1e2f6d7dbe24487aa980ac7be210809": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91271be843084fa183e5160c2713f6c7",
            "placeholder": "​",
            "style": "IPY_MODEL_178573b245114eea9f82b828e8052bad",
            "value": " 2/2 [00:07&lt;00:00,  3.81s/it]"
          }
        },
        "f705da58469a44c0aa258912d58e3385": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_829770d42adc4af7aa4e67faec1c70a8",
            "placeholder": "​",
            "style": "IPY_MODEL_b0ab72881bf84d49865c638b9606a7a4",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "fb9e424c22994338b9eb50e54f38eac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b213337c29864aa6a72c8c0b29362a00",
            "placeholder": "​",
            "style": "IPY_MODEL_85f0199864f045cf91331f331a4a4615",
            "value": " 3/3 [00:06&lt;00:00,  1.78s/it]"
          }
        },
        "fe7a3018794d4d518183900a4301ccce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
